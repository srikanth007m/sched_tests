<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge"><![endif]-->
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 1.5.2">
<meta name="author" content="Copyright (C) 2015, ARM Limited">
<title>SchedTest User Guide</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400">
<style>
/* Asciidoctor default stylesheet | MIT License | http://asciidoctor.org */
/* Remove the comments around the @import statement below when using this as a custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section,summary{display:block}
audio,canvas,video{display:inline-block}
audio:not([controls]){display:none;height:0}
[hidden],template{display:none}
script{display:none!important}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
body{margin:0}
a{background:transparent}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
input[type="search"]{-webkit-appearance:textfield;-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box}
input[type="search"]::-webkit-search-cancel-button,input[type="search"]::-webkit-search-decoration{-webkit-appearance:none}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*:before,*:after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
#map_canvas img,#map_canvas embed,#map_canvas object,.map_canvas img,.map_canvas embed,.map_canvas object{max-width:none!important}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
.antialiased,body{-webkit-font-smoothing:antialiased}
img{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
p.lead,.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{font-size:1.21875em;line-height:1.6}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:none}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #ddddd8;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol,ul.no-bullet,ol.no-bullet{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.no-bullet{list-style:none}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite:before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media only screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7;font-weight:bold}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt,table tr:nth-of-type(even){background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix:before,.clearfix:after,.float-group:before,.float-group:after{content:" ";display:table}
.clearfix:after,.float-group:after{clear:both}
*:not(pre)>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background-color:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre,pre>code{line-height:1.45;color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;text-rendering:optimizeSpeed}
.keyseq{color:rgba(51,51,51,.8)}
kbd{display:inline-block;color:rgba(0,0,0,.8);font-size:.75em;line-height:1.4;background-color:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:-.15em .15em 0 .15em;padding:.2em .6em .2em .5em;vertical-align:middle;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menu{color:rgba(0,0,0,.8)}
b.button:before,b.button:after{position:relative;top:-1px;font-weight:400}
b.button:before{content:"[";padding:0 3px 0 2px}
b.button:after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header:before,#header:after,#content:before,#content:after,#footnotes:before,#footnotes:after,#footer:before,#footer:after{content:" ";display:table}
#header:after,#content:after,#footnotes:after,#footer:after{clear:both}
#content{margin-top:1.25em}
#content:before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #ddddd8}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #ddddd8;padding-bottom:8px}
#header .details{border-bottom:1px solid #ddddd8;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span:before{content:"\00a0\2013\00a0"}
#header .details br+span.author:before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark:before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber:after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #ddddd8;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #efefed;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media only screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background-color:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #efefed;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #efefed;left:auto;right:0}}@media only screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background-color:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
.sect1{padding-bottom:.625em}
@media only screen and (min-width:768px){.sect1{padding-bottom:1.25em}}.sect1+.sect1{border-top:1px solid #efefed}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor:before,h2>a.anchor:before,h3>a.anchor:before,#toctitle>a.anchor:before,.sidebarblock>.content>.title>a.anchor:before,h4>a.anchor:before,h5>a.anchor:before,h6>a.anchor:before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock>caption.title{white-space:nowrap;overflow:visible;max-width:0}
.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>.paragraph:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #ddddd8;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock pre:not(.highlight),.listingblock pre[class="highlight"],.listingblock pre[class^="highlight "],.listingblock pre.CodeRay,.listingblock pre.prettyprint{background:#f7f7f8}
.sidebarblock .literalblock pre,.sidebarblock .listingblock pre:not(.highlight),.sidebarblock .listingblock pre[class="highlight"],.sidebarblock .listingblock pre[class^="highlight "],.sidebarblock .listingblock pre.CodeRay,.sidebarblock .listingblock pre.prettyprint{background:#f2f1f1}
.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;padding:1em;font-size:.8125em}
.literalblock pre.nowrap,.literalblock pre[class].nowrap,.listingblock pre.nowrap,.listingblock pre[class].nowrap{overflow-x:auto;white-space:pre;word-wrap:normal}
@media only screen and (min-width:768px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:.90625em}}@media only screen and (min-width:1280px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:1em}}.literalblock.output pre{color:#f7f7f8;background-color:rgba(0,0,0,.9)}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.listingblock>.content{position:relative}
.listingblock code[data-lang]:before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:#999}
.listingblock:hover code[data-lang]:before{display:block}
.listingblock.terminal pre .command:before{content:attr(data-prompt);padding-right:.5em;color:#999}
.listingblock.terminal pre .command:not([data-prompt]):before{content:"$"}
table.pyhltable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.pyhltable td{vertical-align:top;padding-top:0;padding-bottom:0}
table.pyhltable td.code{padding-left:.75em;padding-right:0}
pre.pygments .lineno,table.pyhltable td:not(.code){color:#999;padding-left:0;padding-right:.5em;border-right:1px solid #ddddd8}
pre.pygments .lineno{display:inline-block;margin-right:.25em}
table.pyhltable .linenodiv{background:none!important;padding-right:0!important}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock blockquote p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote:before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.5em;margin-right:.5ex;text-align:right}
.quoteblock .quoteblock{margin-left:0;margin-right:0;padding:.5em 0;border-left:3px solid rgba(0,0,0,.6)}
.quoteblock .quoteblock blockquote{padding:0 0 0 .75em}
.quoteblock .quoteblock blockquote:before{display:none}
.verseblock{margin:0 1em 1.25em 1em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.05em;color:rgba(0,0,0,.6)}
.quoteblock.abstract{margin:0 0 1.25em 0;display:block}
.quoteblock.abstract blockquote,.quoteblock.abstract blockquote p{text-align:left;word-spacing:0}
.quoteblock.abstract blockquote:before,.quoteblock.abstract blockquote p:first-of-type:before{display:none}
table.tableblock{max-width:100%;border-collapse:separate}
table.tableblock td>.paragraph:last-child p>p:last-child,table.tableblock th>p:last-child,table.tableblock td>p:last-child{margin-bottom:0}
table.spread{width:100%}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all th.tableblock,table.grid-all td.tableblock{border-width:0 1px 1px 0}
table.grid-all tfoot>tr>th.tableblock,table.grid-all tfoot>tr>td.tableblock{border-width:1px 1px 0 0}
table.grid-cols th.tableblock,table.grid-cols td.tableblock{border-width:0 1px 0 0}
table.grid-all *>tr>.tableblock:last-child,table.grid-cols *>tr>.tableblock:last-child{border-right-width:0}
table.grid-rows th.tableblock,table.grid-rows td.tableblock{border-width:0 0 1px 0}
table.grid-all tbody>tr:last-child>th.tableblock,table.grid-all tbody>tr:last-child>td.tableblock,table.grid-all thead:last-child>tr>th.tableblock,table.grid-rows tbody>tr:last-child>th.tableblock,table.grid-rows tbody>tr:last-child>td.tableblock,table.grid-rows thead:last-child>tr>th.tableblock{border-bottom-width:0}
table.grid-rows tfoot>tr>th.tableblock,table.grid-rows tfoot>tr>td.tableblock{border-width:1px 0 0 0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot{border-width:1px 0}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
td>div.verse{white-space:pre}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.unstyled,ol.unnumbered,ul.checklist,ul.none{list-style-type:none}
ul.unstyled,ol.unnumbered,ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1em;font-size:.85em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{width:1em;position:relative;top:1px}
ul.inline{margin:0 auto .625em auto;margin-left:-1.375em;margin-right:0;padding:0;list-style:none;overflow:hidden}
ul.inline>li{list-style:none;float:left;margin-left:1.375em;display:block}
ul.inline>li>*{display:block}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1{padding-right:.75em;font-weight:bold}
td.hdlist1,td.hdlist2{vertical-align:top}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist>table tr>td:first-of-type{padding:0 .75em;line-height:1}
.colist>table tr>td:last-of-type{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left,.imageblock[style*="float: left"]{margin:.25em .625em 1.25em 0}
.imageblock.right,.imageblock[style*="float: right"]{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none}
span.footnote,span.footnoteref{vertical-align:super;font-size:.875em}
span.footnote a,span.footnoteref a{text-decoration:none}
span.footnote a:active,span.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em 0;border-width:1px 0 0 0}
#footnotes .footnote{padding:0 .375em;line-height:1.3;font-size:.875em;margin-left:1.2em;text-indent:-1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background-color:#00fafa}
.black{color:#000}
.black-background{background-color:#000}
.blue{color:#0000bf}
.blue-background{background-color:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background-color:#fa00fa}
.gray{color:#606060}
.gray-background{background-color:#7d7d7d}
.green{color:#006000}
.green-background{background-color:#007d00}
.lime{color:#00bf00}
.lime-background{background-color:#00fa00}
.maroon{color:#600000}
.maroon-background{background-color:#7d0000}
.navy{color:#000060}
.navy-background{background-color:#00007d}
.olive{color:#606000}
.olive-background{background-color:#7d7d00}
.purple{color:#600060}
.purple-background{background-color:#7d007d}
.red{color:#bf0000}
.red-background{background-color:#fa0000}
.silver{color:#909090}
.silver-background{background-color:#bcbcbc}
.teal{color:#006060}
.teal-background{background-color:#007d7d}
.white{color:#bfbfbf}
.white-background{background-color:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background-color:#fafa00}
span.icon>.fa{cursor:default}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note:before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip:before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning:before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution:before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important:before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background-color:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]:after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
h1,h2{letter-spacing:-.01em}
dt,th.tableblock,td.content{text-rendering:optimizeLegibility}
p,td.content{letter-spacing:-.01em}
p strong,td.content strong{letter-spacing:-.005em}
p,blockquote,dt,td.content{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background-color:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@media print{@page{margin:1.25cm .75cm}
*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare):after,a[href^="https:"]:not(.bare):after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]:after{content:" (" attr(title) ")"}
pre,blockquote,tr,img{page-break-inside:avoid}
thead{display:table-header-group}
img{max-width:100%!important}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #ddddd8!important;padding-bottom:0!important}
.sect1{padding-bottom:0!important}
.sect1+.sect1{border:0!important}
#header>h1:first-child{margin-top:1.25rem}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em 0}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span:before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]:before{display:block}
#footer{background:none!important;padding:0 .9375em}
#footer-text{color:rgba(0,0,0,.6)!important;font-size:.9em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
</style>
</head>
<body class="article">
<div id="header">
<h1>SchedTest User Guide</h1>
<div class="details">
<span id="author" class="author">Copyright (C) 2015, ARM Limited</span><br>
</div>
<div id="toc" class="toc">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#Introduction">1. Introduction</a></li>
<li><a href="#SchedTestSuite">2. SchedTest Suite</a>
<ul class="sectlevel2">
<li><a href="#SchedTestSuite_Installation">2.1. Installation</a></li>
<li><a href="#SchedTestSuite_Usage">2.2. Usage</a></li>
<li><a href="#SchedTestSuite_Packaging">2.3. Binary installation package</a></li>
<li><a href="#SchedTestSuite_Workflow">2.4. Typical usage workflow</a></li>
<li><a href="#SchedTestSuite_Components">2.5. Components</a></li>
</ul>
</li>
<li><a href="#TestSuites">3. Test Suites Description</a>
<ul class="sectlevel2">
<li><a href="#suite_basic">3.1. "Basic" Test Suite</a></li>
<li><a href="#suite_core">3.2. "Core" Test Suite</a></li>
<li><a href="#suite_extended">3.3. "Extended" Test Suite</a></li>
<li><a href="#suite_hwbreakpoint">3.4. "HwBreakpoint" Test Suite</a></li>
<li><a href="#suite_irqs">3.5. "IRQs" Test Suite</a></li>
<li><a href="#suite_loadbalance">3.6. "Load Balance" Test Suite</a></li>
<li><a href="#suite_non_functional_suite">3.7. "Non Functional" Test Suite</a></li>
<li><a href="#suite_pmu">3.8. "PMU" Test Suite</a></li>
<li><a href="#suite_regression_suite">3.9. "Regression" Test Suite</a></li>
<li><a href="#suite_scaleinvariance">3.10. "Scale Invariance" Test Suite</a></li>
<li><a href="#suite_taskpacking">3.11. "TaskPacking" Test Suite</a></li>
<li><a href="#suite_thresholds">3.12. "Thresholds" Test Suite</a></li>
<li><a href="#suite_usecases">3.13. "Use-Cases" Test Suite</a></li>
<li><a href="#suite_ipa_functional">3.14. "IPA Functional" Test Suite</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="Introduction">1. Introduction</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This document describes the test framework and the test suite for testing
the ARM big.LITTLE MP scheduler extensions. This framework includes
multiple test suites aimed at validating different functional aspects of
the big.LITTLE MP scheduler extensions.</p>
</div>
<div class="paragraph">
<p>In addition, this framework also includes functional tests for ARM&#8217;s Intelligent
Power Allocation (IPA) framework.</p>
</div>
<div class="paragraph">
<p>This document is organized as follow:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="#SchedTestSuite">Section 2</a> provides instructions on how to install and use
the test suite. The reading of this section is mandatory in order to
validate the integration of the big.LITTLE MP patchset on a given target platform.</p>
</li>
<li>
<p><a href="#TestSuites">Section 3</a> details the main goals of each test suite
component and the corresponding test cases. This section is useful to understand how a
specific test case works and to pinpoint the possible reasons for a test failure.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="SchedTestSuite">2. SchedTest Suite</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The main goal of this test suite is to support the validation of a
big.LITTLE MP scheduler configuration. This section explains:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="#SchedTestSuite_Installation">How to install the suite</a></p>
</li>
<li>
<p><a href="#SchedTestSuite_Usage">How to use the suite shell</a></p>
</li>
<li>
<p><a href="#SchedTestSuite_Configuration">How to configure the test suite</a></p>
</li>
<li>
<p><a href="#SchedTestSuite_Workflow">Usage workflow and example</a></p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="SchedTestSuite_Installation">2.1. Installation</h3>
<div class="paragraph">
<p>The test suite must be installed in a HOST machine which will be used to
configure and build the suite.  This is the list of mandatory tools which are
expected to be available in the HOST machine:</p>
</div>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>Essential building tools (e.g., the “build-essential” packages on Debian
based systems)</p>
</li>
<li>
<p>An ARM cross-compilation toolchain on your path (e.g.
arm-linux-gnueabihf-gcc)</p>
</li>
<li>
<p>Autotools (i.e. autoconf, automake and libtoolize)</p>
</li>
<li>
<p>SSH client (for Linux targets)</p>
</li>
<li>
<p>ADB binary (for Android targets)</p>
</li>
<li>
<p>ncurses library (to run the Kconfig configuration tool)</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>For example, in Ubuntu 12.04 you can get a working environment suitable for
SchedTest compilation by running this command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">  $ sudo apt-get install build-essential autoconf automake libtool \
                 git-core ncurses-dev moreutils gawk curl aterm</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can download the stand-alone Android SDK Tools packages, which provide
the basic SDK tools to interact with an Android device, following the
instruction on the dedicated
<a href="http://developer.android.com/sdk/index.html#Other">Android Developers Tools</a>
webpage.</p>
</div>
<div class="paragraph">
<p>In the rest of this documentation we assume the user has installed the
SchedTest suite in the <code>&lt;SchedTestFolder&gt;</code>.</p>
</div>
<div class="paragraph">
<div class="title">Note on Linux target access</div>
<p>The simplest way to get access to a Linux target via SSH to run the tests
is by logging in as <code>root</code> user without a password. To enable such an access
please ensure that these conditions are meet:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The root user has an empty password, i.e. you have this entry on your
<code>/etc/shadows</code> configuration file: <code>root::16486:0:99999:7:::</code>, notice the
pair <code>::</code> after the username</p>
</li>
<li>
<p>You OpenSSH server is configured with these options:</p>
<div class="literalblock">
<div class="content">
<pre>PermitRootLogin yes
PermitEmptyPasswords yes
PasswordAuthentication yes
UsePAM no</pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="SchedTestSuite_Usage">2.2. Usage</h3>
<div class="paragraph">
<p>The main steps to run the SchedTest suite are:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Configuring the suite</p>
</li>
<li>
<p>Building and installing the configured suite locally</p>
</li>
<li>
<p>Installing on the target and running the tests</p>
</li>
<li>
<p>Collecting and analyzing the results</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The following sections details each one of these steps.  It is worth knowing
that the suite provides a shell configuration which makes it easy to access
the main commands.  To enable such a shell the user should source the
<code>init_env</code> configuration file provided in the root of the SchedTest suite,
i.e.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ . init_env</code></pre>
</div>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<img src="./images/icons/warning.png" alt="Warning">
</td>
<td class="content">
the provided configuration is just for the BASH shell.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Once the shell has been configured this is the appearance of the SchedTest
Shell:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/SchedTestShell/SchedTestShell.png" alt="SchedTest Shell Screenshot" width="512">
</div>
</div>
<div class="paragraph">
<p>Online help is always available within the SchedTest shell, you can access
it with the command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-help</code></pre>
</div>
</div>
<div class="paragraph">
<p>Which gives you access to a short list of the main available commands:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/SchedTestShell/OnlineHelp.png" alt="Online Help" width="512">
</div>
</div>
<div class="sect3">
<h4 id="SchedTestSuite_Configuration">2.2.1. SchedTest Suite Configuration</h4>
<div class="paragraph">
<p>The configuration of the suite is meant to define which tests should be run on
the target as well as all the required options to properly deploy the suite on
the target. Also run the set of required tests and to collect execution traces and
results.
Such a configuration is supported by a <code>schedtest-config</code> command and the
Kconfig configuration tool.</p>
</div>
<div id="Configuration_Command" class="paragraph">
<div class="title">The SchedTest Configuration Command</div>
<p>The <code>schedtest-config</code> command allows the user to:</p>
</div>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>Load a predefined configuration, among the ones available in the local
installation</p>
</li>
<li>
<p>Setup a new configuration or tune the current one</p>
</li>
<li>
<p>Save the current configuration as a default config</p>
</li>
<li>
<p>Reset completely the current configuration</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>All the supported configuration options are reported by issuing the command
without any arguments:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/SchedTestShell/SchedTest_Config_Command.png" alt="SchedTest configuration command">
</div>
</div>
<div class="paragraph">
<p>The available local configurations are listed by this command and they can be
loaded by simply passing the corresponding name as the first parameter.
For example, to load the default configuration for a TC2 board running Android
you just need to run this command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-config tc2</code></pre>
</div>
</div>
<div class="paragraph">
<p>The names of the provided configurations have been defined using the
"<code>target[_linux][_full]</code>" pattern, where:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">target</dt>
<dd>
<p>is the name of a supported board</p>
</dd>
<dt class="hdlist1">_linux</dt>
<dd>
<p>is an optional tag to identify a configuration for a Linux target, if
this tag is missing the configuration is assumed to be for an Android target</p>
</dd>
<dt class="hdlist1">_full</dt>
<dd>
<p>is an optional tag to identify a configuration which runs all the test
suites and relative testacases supported by the specified target</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>Thus, for example:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>tc2_linux</code> is the default configuration for a TC2 board running Linux</p>
</li>
<li>
<p><code>juno_full</code> is the default configuration for a Juno board running Android</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Once a default configuration has been loaded it is worth checking always the
options using the Kconfig interface.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<img src="./images/icons/warning.png" alt="Warning">
</td>
<td class="content">
Some configuration settings depend on the specific targets and they
require manual tuning.
For example, the IP address of a Linux target must always be properly
configured using the dedicated Kconfig option.
</td>
</tr>
</table>
</div>
<div id="Configuration_Kconfig" class="paragraph">
<div class="title">The Kconfig configuration interface</div>
<p>KConfig is the standard tool used to configure a Linux kernel build, thus most
of the users of the SchedTest suite are expected to be familiar with this tool.</p>
</div>
<div class="paragraph">
<p>To start the Kconfig tool to check or update the current configuration you can
use the command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-config menu</code></pre>
</div>
</div>
<div class="paragraph">
<p>which will open an ncurses based interface</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/SchedTestShell/Kconfig_MainMenu.png" alt="Kconfig main menu">
</div>
</div>
<div class="paragraph">
<p>The configuration options for the SchedTest suite are grouped in five main
categories:</p>
</div>
<div id="Configuration_Platform" class="dlist">
<dl>
<dt class="hdlist1">Platform</dt>
<dd>
<p>Defines the target we want to test, which can be either a Linux or Android
system, and the specific board, which can be selected among the set of
supported boards.
Among these options this menu allows the verification and (eventually)
the customisation of  some target specific options, such as the number and IDs of big and LITTLE
cores available on the target, the range of supported operating frequencies and
the prefix for the toolchain to be used for the compilation of the assets to
deploy on the target.</p>
</dd>
</dl>
</div>
<div class="imageblock">
<div class="content">
<img src="images/SchedTestShell/Kconfig_PlatformMenu.png" alt="The Platform menu">
</div>
</div>
<div id="Configuration_Suites" class="dlist">
<dl>
<dt class="hdlist1">Suites</dt>
<dd>
<p>This menu lists all the supported test suites which can be executed on the
configured target platform.
Each suite can be independently selected and in that case by entering the
corresponding submenu, the testcases of the corresponding suite are listed.
Each testcase can be independently selected.</p>
</dd>
</dl>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<img src="./images/icons/warning.png" alt="Warning">
</td>
<td class="content">
only the selected testcases will be installed in the target
and executed for the corresponding testcase.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<img src="./images/icons/note.png" alt="Note">
</td>
<td class="content">
if you are interested on a specific testcase, for example because it was
reported to fail and you want to run it multiple times to check if the failure
is constant, you should disable all the test suites but the one of the testcase
of interest. Within this suite enable only the testcase of interest.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For example, the following two screenshots show how to configure the execution
of the only <code>core_test_scn3.2a</code> testcase.
This is done by enabling only the basic suite:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/SchedTestShell/Kconfig_Suite_Basic.png" alt="Single suite selection example">
</div>
</div>
<div class="paragraph">
<p>and then selecting the single testcase of interest:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/SchedTestShell/Kconfig_Suite_BasicScn32a.png" alt="Single testcase selection example">
</div>
</div>
<div id="Configuration_Components" class="dlist">
<dl>
<dt class="hdlist1">Components</dt>
<dd>
<p>This is just a utility menu which shows the binary components provided by the
SchedTest suite which are going to be installed on the target.</p>
</dd>
</dl>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<img src="./images/icons/caution.png" alt="Caution">
</td>
<td class="content">
the user is not expected to tune the options of this menu, which will
likely be hidden in a future version.
</td>
</tr>
</table>
</div>
<div id="Configuration_Deployment" class="dlist">
<dl>
<dt class="hdlist1">Deployment</dt>
<dd>
<p>The deployment menu collects all the configuration options which allow to
define how the SchedTest suite will be deployed on the target. Some of these
options deserve a better explanation:</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>The <em>deployment path</em> is the path on the target where the suite is going to be
installed and the testcases executed.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<img src="./images/icons/warning.png" alt="Warning">
</td>
<td class="content">
The <code>Deployment path</code> must be on a writable partition of a
medium on the target device and pointing to a folder with writable permission
for the user used to connect with the board.
</td>
</tr>
</table>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<img src="./images/icons/caution.png" alt="Caution">
</td>
<td class="content">
The SchedTest suite requires also a writable <code>/tmp</code> folder
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The <em>tasklibrary calibration</em> file is a textual file which is generated by the
tasklibrary component the first time it is executed on the target. The goal of
this file is to measure and collect all the calibration values required to
generate a required amount of load on each and every CPU of the target system.
Generating such a file requires minutes and thus it can have a significant
impact on the overall tests execution time, especially when some simple
tests need to be executed.
It is enough to build this file just one time for each new target platform.
An option allows the calibration file to be backed up once it has been built the first
time on a new target.
Once this file has been backed up, the same option allows the reuse of a previously
built calibration file by pushing it on the target along with the other assets.</p>
</div>
<div class="paragraph">
<p>An <em>SSH or ADB configuration</em> section is also exposed by the menu, depending on
the configured target being Linux or Android.
These options allow the proper configuration of the corresponding tool to properly
access the target. For example, an IP address should be specified to access a
Linux target.</p>
</div>
<div class="paragraph">
<p>Finally, the deployment section allows the generation of an
<em>auto-installation package</em> for the current SchedTest configuration. The usage
of self-configuration packages is explained in a following section.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/SchedTestShell/Kconfig_Deployment.png" alt="Deployment configuration">
</div>
</div>
<div id="Configuration_Results" class="dlist">
<dl>
<dt class="hdlist1">Results</dt>
<dd>
<p>This menu allows the selection of some specific options regarding results collection.
Specifically, via this menu it is possible to define how many runs should be run
for each testcase executed.</p>
</dd>
</dl>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<img src="./images/icons/warning.png" alt="Warning">
</td>
<td class="content">
This option affects <strong>all</strong> the configured testcases. Thus, it is
usually suggested to run a first batch of experiments using just one iteration
and then reconfigure the suite to have multiple runs but just for the subset of
testcases which have failed.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>This menu allows you also to force the collection of binary traces which are
generated during experiments.
In that case, binary traces will be collected on the host machine where they
will be available for further analysis to investigate the reasons for a
testcase failure.</p>
</div>
<div class="paragraph">
<p>Finally, an advanced Ftrace configuration option allows to define which events
should be collected during an experiment. This can be useful to
better investigate the reasons for a testcase failure.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/SchedTestShell/Kconfig_Results.png" alt="Results configuration">
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="SchedTestSuite_Packaging">2.3. Binary installation package</h3>
<div class="paragraph">
<p>The SchedTest suite could be built as a standalone binary installation
and execution package. This option allows the build of preconfigured releases
so as to run the suite on multiple targets or to easily setup a collection
of regression tests.</p>
</div>
<div class="paragraph">
<p>The binary release package is built based on the current active configuration.
The set of selected test suites and test cases are packed into a self-extracting
bash archive along with a minimum set of scripts required which allow
deployment of the tests on a Linux or Android target, the trigger of their execution and
to collect back the results.</p>
</div>
<div class="paragraph">
<p>To generate a binary installation package, the SchedTest shell provides the
command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-package [name]</code></pre>
</div>
</div>
<div class="paragraph">
<p>The output of such a command will be similar to the one reported on this
screenshot:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/SchedTestShell/SchedTest_Package.png" alt="Results of packaging command">
</div>
</div>
<div class="paragraph">
<p>The full path of the generated installation package is reported in the putput.
The name of the package to generate could be specified as an optional parameter,
by default it is set to "schedtest".</p>
</div>
<div class="paragraph">
<div class="title">Binary package usage</div>
<p>The tests collected into a binary installation package could be executed on
a defined target by simply executing the package and following the
simple on-screen instructions.</p>
</div>
<div class="paragraph">
<p>The following figure reports an example of the available execution options:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/SchedTestShell/SchedTest_BinaryInstallation.png" alt="Binary package execution options">
</div>
</div>
<div class="paragraph">
<p>Thus, when the binary package is executed a new folder is created which contains
the binary installation of the SchedTest suite as well as the <code>schedtest</code>
script which allows the deployment and execution of this suite on a specified target.</p>
</div>
<div class="paragraph">
<p>The only available options allow the definition of the target for the
experiment. For example, to run an a Linux TC2 target, the required command
line will be:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest -l -i &lt;TARGET_IP_ADDRESS&gt; -u &lt;USERNAME&gt; -p &lt;PASSWORD&gt;</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="SchedTestSuite_Workflow">2.4. Typical usage workflow</h3>
<div class="paragraph">
<p>This section describes a typical usage workflow assuming the test suite has been
already installed in the <code>&lt;SchedTestFolder&gt;</code>.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Enter the suite main folder and load the SchedTest shell</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ cd $SCHEDTESTFOLDER
$ . ./init_env</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>(Optional) reset the suite configuration and load a default configuration for
the selected target, in this example we assume a TC2 board:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-config reset
$ schedtest-config tc2</code></pre>
</div>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<img src="./images/icons/warning.png" alt="Warning">
</td>
<td class="content">
a configuration reset is required each time you want to switch the
current target.  There are some internal configuration options which
are target related but these are only updated when starting with a configuration reset.
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Check the current configuration and eventually tune the required
suites/testcases to run, the deployment options and the results collection
options</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-config menu</code></pre>
</div>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<img src="./images/icons/caution.png" alt="Caution">
</td>
<td class="content">
check the target access configuration options under the deployment
menu. For android, ADB should be properly configured. For a Linux target the IP
address of the board should be configured.
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<img src="./images/icons/tip.png" alt="Tip">
</td>
<td class="content">
you can speedup test execution by using a backup calibration file,
which can be specified in the Deployment menu.
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Install the configured suite both locally as well as on the target</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-install</code></pre>
</div>
</div>
<div class="paragraph">
<p>A detailed log of the installation is reported in the console. If everything
completes successfully you should get a notice that the suite has been
installed in the specified target folder.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/SchedTestShell/SchedTest_Shell_Install.png" alt="Install log example">
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<img src="./images/icons/note.png" alt="Note">
</td>
<td class="content">
The local "out" folder contains an image of the target content. You can
check the local "out" folder to verify what has been installed on the target.
This "out" folder will contains also the results of the tests once they have
been completed and pulled from the target.
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Run all the configured test suites on the target</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-run</code></pre>
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="images/SchedTestShell/SchedTest_Shell_Run.png" alt="Run log example">
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<img src="./images/icons/note.png" alt="Note">
</td>
<td class="content">
this command will execute all the testcases of the configured enabled test
suites.
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<img src="./images/icons/tip.png" alt="Tip">
</td>
<td class="content">
you can limit execution to the testcases of a single test suite by
specifying the test suite name as an argument of the <code>schedtest-run</code> command.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>You can follow the test execution by looking at the console log, which reports
the results for each testcase as soon as it has completed. Once all the tests
have been completed you get an overall report of the testcases results. For
example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>=== Suite [extended_suite @ 2015-02-20 09:24:11]
Testcase: extd_test_scn01.1        Status: pass Success Ratio: 1.000000
Testcase: extd_test_scn01.2a       Status: pass Success Ratio: 1.000000
Testcase: extd_test_scn01.4        Status: pass Success Ratio: 1.000000
Testcase: extd_test_scn03.1        Status: pass Success Ratio: 1.000000
Testcase: extd_test_scn03.2a       Status: FAIL Success Ratio: 0.000000
  Reference: file:////work/derkling/sched_tests/docs/index.html#test_extd_test_scn03.2a
  Detailed testcase report on:
    out/suites/extended/testcases/extd_test_scn03.2a/extd_test_scn03.2a_05-03-2015-18-41-16.res
Testcase: extd_test_scn03.4        Status: pass Success Ratio: 1.000000
Testcase: extd_test_scn04.1        Status: pass Success Ratio: 1.000000
Testcase: extd_test_scn04.2        Status: pass Success Ratio: 1.000000

Overal results:
Passed: 7
Failed: 1</code></pre>
</div>
</div>
<div class="paragraph">
<p>In this example all the testcases of the "Extended" suite have been executed
and one of them failed, namely <code>extd_test_scn03.2a</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<img src="./images/icons/note.png" alt="Note">
</td>
<td class="content">
for each failed test a link to the embedded HTML
documentation is provided which describes the experiment.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For each failed test case, the referenced report contains a detailed log of the
experiment execution. Looking at this logfile is helpful to identify
the possible reasons for a failure.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Reconfigure the suite to focus on failed test</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>In the some tests should fail, it is usually beneficial to run
only the failing test cases with an increased number of iterations. To do that, just
start the configuration menu and disable all the test suites/cases but the one
of interest and set an higher number of iterations (e.g. 10). Install and run
again the newly configured suite and check the "passing ratio" of the specific
test case.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Check tests execution results</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The results of the tests executed are collected locally and are available in
the <code>results.txt</code> file within the <code>./out</code> folder.
These results can always be viewed on screen using the dedicated shell
command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-results</code></pre>
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="images/SchedTestShell/SchedTest_Shell_Results.png" alt="Results example">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Archive the collected results</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>All the results available in the output folder can be collected and archived
into a tarball using the dedicated shell command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-archive</code></pre>
</div>
</div>
<div class="paragraph">
<p>This command will generate a <code>tar.gz</code> archive into the local folder which is
named similar to this example:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>testrun_20-02-2015-17-04-17.tar.gz</pre>
</div>
</div>
<div class="paragraph">
<p>ie a <code>testrun_</code> followed by the date and timestamp of when the archive
has been created.</p>
</div>
<div class="paragraph">
<p>This archive contains the complete content of the local output folder, which
means: test cases and collected results. Thus, it is a suitable archive to be
eventually circulated and/or installed by hand on another similar target
to agian run the contained test cases.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/SchedTestShell/SchedTest_Archive.png" alt="Archive example">
</div>
</div>
</div>
<div class="sect2">
<h3 id="SchedTestSuite_Components">2.5. Components</h3>
<div class="paragraph">
<p>This section briefly introduces and describes some of the main tools
that are a part of the test suite and that are used internally by the commands of the SchedTest
suite shell. In the normal case, it is not required to know what these
commands are and how they work.  Advanced users can find the
description useful to better understand how certain tests are defined and how they are
executed.</p>
</div>
<div class="sect3">
<h4 id="SchedTestSuite_Testrunner">2.5.1. Testrunner</h4>
<div class="paragraph">
<p>The testrunner application is the user entry point for the test harness
framework.
This application is installed by the SchedTest suite on the target device and
is the actual tool used to trigger the execution of the installed tests. The
user is not required to interact directly with this tool, however it can be
interesting to know how it works in case some advanced experiments or testing
scenarios not covered by the suite needs to be executed by an advanced user.</p>
</div>
<div class="paragraph">
<p>It is worth knowing that these tools rely on a simple DB of available
tests, which is represented by the TXT file named <code>suites.txt</code> that is present
in the <code>./out</code> installation folder. Only the suites listed in
that file can be executed by the testrunner component.</p>
</div>
<div class="paragraph">
<div class="title">Usage Examples</div>
<p>The following are some usage examples that showcase the functionality of
testrunner.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<img src="./images/icons/note.png" alt="Note">
</td>
<td class="content">
this tool is meant to be executed on the target, where it is available at
the root of the installation folder.
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>display all the existing suites known to testrunner:</p>
<div class="literalblock">
<div class="content">
<pre>$ testrunner --list</pre>
</div>
</div>
</li>
<li>
<p>list all test cases composing the <em><code>example</code></em> suite</p>
<div class="literalblock">
<div class="content">
<pre>$ testrunner --list --suite example</pre>
</div>
</div>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<img src="./images/icons/note.png" alt="Note">
</td>
<td class="content">
only the suites listed in the <em><code>suites.txt</code></em> file are available for
execution
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>run <em><code>testcase0</code></em> that belongs to suite <em><code>example</code></em> once:</p>
<div class="literalblock">
<div class="content">
<pre>$ testrunner --run --suite example --testcase testcase0</pre>
</div>
</div>
</li>
<li>
<p>run 10 times every testcase in suite <em><code>example</code></em>:</p>
<div class="literalblock">
<div class="content">
<pre>$ for i in `testrunner --list --suite example`; do
    testrunner --run --n 10 --suite example --testcase $i
  done</pre>
</div>
</div>
</li>
<li>
<p>prints the description of the testcase <em><code>tc1</code></em> which belongs to suite <em><code>example</code></em>:</p>
<div class="literalblock">
<div class="content">
<pre>$ testrunner --desc --suite example --testcase tc1</pre>
</div>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="SchedTestSuite_Tasklibrary">2.5.2. Tasklibrary</h4>
<div class="paragraph">
<div class="title">Load sequence language</div>
<p>A load sequence is made up of a number of timed points, where the time is
specified in milliseconds. All times are relative to the start of the load
trace, <strong>not</strong> the previous timed point. At each point, the load to be generated
relative to a given CPU&#8217;s calibration is given as a percentage.</p>
</div>
<div class="paragraph">
<p>For example, to start a 50% load equivalent to that of CPU0 at 1[s], the timed
point looks like:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>1000,0.50</pre>
</div>
</div>
<div class="paragraph">
<p>Which follows the standard format of:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>&lt;time in ms&gt;,&lt;cpu number&gt;.&lt;percentage load&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>The timed points can be joined together to form a sequence using a separator.</p>
</div>
<div class="literalblock">
<div class="content">
<pre>1000,0.50:2000,1.100</pre>
</div>
</div>
<div class="paragraph">
<p>This starts a load equivalent to 50% of CPU0 after 1[s], and after 2[s]
switches to 100% of CPU1</p>
</div>
<div class="paragraph">
<div class="title">Interpolated Loads</div>
<p>A timed point can be extended to generate a linear interpolation based on 10
intervals between two calibration points. To do this, use a <em>-</em> symbol between
two timed points, like so:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>1000,0.50-2000,1.100</pre>
</div>
</div>
<div class="paragraph">
<p>This represents a linear interpolation over 1s between 50% of CPU0 and 100% of CPU1.</p>
</div>
<div class="paragraph">
<div class="title">CPU Identifiers</div>
<p>When selecting load to generate, the assumption is that task placement will be
controlled by the environment.
There is no control in the language over where the load is executed - it runs
in the context of the main thread of the running executable.</p>
</div>
<div class="paragraph">
<p>CPU identifiers used in the language refer to the calibration data for a given
CPU. There are however two special CPU identifiers which we have not
shown so far.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>B or b - selects the CPU with the largest calibrated number for 100% load</p>
</li>
<li>
<p>L or l - selects the CPU with the lowest calibrated number for 100% load</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>e.g. generate load equivalent to 50% of the biggest CPU available looks like:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>1000,B.50</pre>
</div>
</div>
<div class="paragraph">
<div class="title">Ending a load sequence</div>
<p>A load sequence does not need to have an explicit end. When one is not present
the previous load point will be maintained until the exe is killed.
If you wish to end the load generation at a specific time, then you can use end
in place of a CPU:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>0,0.0:1000,0.100:2000,end</pre>
</div>
</div>
<div class="paragraph">
<p>is a load sequence starting at 100% after 1[s] of idle and ending after 2[s].
The <em>end tag</em> must be the last tag and there can be only one.</p>
</div>
<div class="paragraph">
<div class="title">Load Sequence Files</div>
<p>In order to make it easy to share test loads, the load sequences can be stored
in a plain ascii text file. The format is exactly the same and line endings are
ignored.
For convenience, if a separator is not present but a line ending is, the
default <code>:</code> separator is assumed.</p>
</div>
<div class="paragraph">
<div class="title">Changing Priority</div>
<p>You can optionally set the process priority in any step by including an
additional dot field in a step. The priority is set like <em>nice</em>, so is between
-20 and 20 with the default being read from the system.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Example</dt>
<dd>
<p>this load sequence starts at <em>system default</em> nice, goes to nice -20 at 1[s],
stays at nice -20 at 2[s] and to nice 0 at 3[s]:</p>
<div class="literalblock">
<div class="content">
<pre>0,l.10:1000,l.10.-20:2000,l.10:3000,l.10.0</pre>
</div>
</div>
</dd>
</dl>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<img src="./images/icons/note.png" alt="Note">
</td>
<td class="content">
If a nice value is not set at the beginning, the current priority is read
and used.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<img src="./images/icons/note.png" alt="Note">
</td>
<td class="content">
When a nice value is set, it remains in place until you change it.
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="SchedTestSuite_FtraceAnalyzer">2.5.3. Ftrace Analyzer</h4>
<div class="paragraph">
<p>This tool allows the analysis of a trace of kernel events looking for a set of
configured events regarding tasks scheduled on different CPUs. Different kinds
of analyses are supported, each one being provided by a plugin. Each
plugin/analysis can be configured by specifiying a set of environmental
variable to define thinks such as: tasks of interest, expected scheduling on
big or LITTLE CPUs and time for their migration.</p>
</div>
<div class="literalblock">
<div class="title">Usage</div>
<div class="content">
<pre>./ftrace -t tracefile -l ./libanalizis.so</pre>
</div>
</div>
<div class="paragraph">
<p>Will analyze the <em>tracefile</em> trace which is expected to be TXT trace generated
by reading the <code>trace</code> attribute of the sysfs kernel tracer interface or by
using the <em>report</em> command of the <code>trace-cmd</code> tool.</p>
</div>
<div class="paragraph">
<p>Hereafter is a short description of the two main useful plugins which are used
by some testcases.</p>
</div>
<div class="paragraph">
<div class="title">libbiglittleswitch.so.1.0.0</div>
<p>The goal of this plugin is to verify the transition from an initial condition to
a final one for a specified set of tasks. This plugin can be used to verify,
for example, that a specified workload is moving from LITTLE CPUs to big ones
within a specified time interval.</p>
</div>
<div class="paragraph">
<p>To confiugre the plugin these environment variables can be defined:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Conf start</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>START_BIG = pid0,pid1,&#8230;&#8203;</p>
</li>
<li>
<p>START_BIG_PRIORITY = pid0_prio,pid1_prio,&#8230;&#8203;</p>
</li>
<li>
<p>START_LTTILE = pid100,pid101,&#8230;&#8203;</p>
</li>
<li>
<p>START_LITTLE_PRIORITY = pid100_prio,pid101_prio,&#8230;&#8203;</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Conf end</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>END_BIG = pid0,pid1,&#8230;&#8203;</p>
</li>
<li>
<p>END_BIG_PRIORITY = pid0_prio,pid1_prio,&#8230;&#8203;</p>
</li>
<li>
<p>END_LTTILE = pid100,pid101,&#8230;&#8203;</p>
</li>
<li>
<p>END_LITTLE_PRIORITY = pid100_prio,pid101_prio,&#8230;&#8203;</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Time to move from first in milliseconds</dt>
<dd>
<p>From EXPECTED_CHANGE_TIME_MS_MIN to EXPECTED_CHANGE_TIME_MS_MAX</p>
</dd>
<dt class="hdlist1">Minimum time in end state in milliseconds</dt>
<dd>
<p>From EXPECTED_TIME_IN_END_STATE_MS</p>
</dd>
</dl>
</div>
<div class="paragraph">
<div class="title">libprocess_matrix.so.1.0.0</div>
<p>The goal of this plugin is to compute and eventually verify the overall
execution time of a specified workload on different CPUs. This plugin can be
used to verify, for example, that a specified set of tasks are scheduled for
execution up to a maximum percentage of the overall execution time on a
specified set of CPUS.</p>
</div>
<div class="paragraph">
<p>To configure the plugin these environment variables can be defined:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Conf analysis interval</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>PID</p>
</li>
<li>
<p>START</p>
</li>
<li>
<p>STOP</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Tasks residency checks</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>CPUS_MASK mask of the CPUs to consider</p>
</li>
<li>
<p>USAGE_MIN minimum percentage of time tasks can be scheduled on the CPUs defined by the CPUS_MASK</p>
</li>
<li>
<p>USAGE_MAX maximum percentage of time tasks can be scheduled on the CPUs defined by the CPUS_MASK</p>
</li>
<li>
<p>TIME_MIN minimum amount of time tasks can be scheduled on the CPUs defined by the CPUS_MASK</p>
</li>
<li>
<p>TIME_MAX maximum amount of time tasks can be scheduled on the CPUs defined by the CPUS_MASK</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<div class="title">Examples</div>
<p>Store ftrace in binary format in file_to_store_my_trace:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>./ftrace -s file_to_store_my_trace</pre>
</div>
</div>
<div class="paragraph">
<p>See what a library, e.g. libanalyzis4.so, is doing:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>./ftrace -q ./libanalyzis4.so</pre>
</div>
</div>
<div class="paragraph">
<p>Show all available library internally or in current directory</p>
</div>
<div class="literalblock">
<div class="content">
<pre>./ftrace [-L]</pre>
</div>
</div>
<div class="paragraph">
<p>Show all available library internally or in current directory and their description:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>./ftrace [-LL]</pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="TestSuites">3. Test Suites Description</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This section provides a detailed description of each test case provided by the
SchedTest suite.  Test cases are collected into test suites, each one targeting
the verification of a specific set of functionalities.</p>
</div>
<div class="paragraph">
<p>Here is the list of the currently supported test suites:</p>
</div>
<div class="ulist">
<div class="title">Platform Check Suites</div>
<ul>
<li>
<p><a href="#suite_hwbreakpoint">hwbreakpoint</a></p>
</li>
<li>
<p><a href="#suite_pmu">pmu</a></p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">big.LITTLE MP Scheduler Extensions - Integration Checks Suites</div>
<ul>
<li>
<p><a href="#suite_basic">basic</a></p>
</li>
<li>
<p><a href="#suite_irqs">irqs</a></p>
</li>
<li>
<p><a href="#suite_thresholds">thresholds</a></p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">big.LITTLE MP Scheduler Extensions - Basic Checks Suites</div>
<ul>
<li>
<p><a href="#suite_core">core</a></p>
</li>
<li>
<p><a href="#suite_extended">extended</a></p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">big.LITTLE MP Scheduler Extensions - Advanced Checks Suites</div>
<ul>
<li>
<p><a href="#suite_taskpacking">taskpacking</a></p>
</li>
<li>
<p><a href="#suite_scaleinvariance">scaleinvariance</a></p>
</li>
<li>
<p><a href="#suite_loadbalance">loadbalance</a></p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Stability Assessment Suites</div>
<ul>
<li>
<p><a href="#suite_non_functional">non_functional</a></p>
</li>
<li>
<p><a href="#suite_regression">regression</a></p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="suite_basic">3.1. "Basic" Test Suite</h3>
<div class="paragraph">
<div class="title">Goal</div>
<p>The primary aim of the test cases within basic_suite is to validate and confirm
the basic integration of big.LITTLE MP patches. The intend of the test design
was to assert the specification of key kernel configurations or attributes as
needed by big.LITTLE MP patches.</p>
</div>
<div class="paragraph">
<p>To start the execution of just this test:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-run basic</code></pre>
</div>
</div>
<div class="paragraph">
<p>Following is the list of supported tests</p>
</div>
<div class="sect3">
<h4 id="test_basiccheck">3.1.1. basiccheck</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Use heavy and light load generating threads to confirm that high load threads
go to <em>fast</em> CPUs and low load threads go to <em>slow</em> CPUs using the big.LITTLE
MP scheduler extensions.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>The intent of the test design is to generate synthetic tasks with specific load
characteristics, and check if the light tasks are running on the LITTLE cores
and the heavy tasks are running on the big cores. The big and LITTLE CPU lists are
obtained from the proc interface <code>/proc/cpuinfo</code>.</p>
</div>
<div class="paragraph">
<p>The tasklibrary generates initially a low load which is more than the number of
LITTLE cores in the system. This is to check if the low load is going to the
LITTLE core only and not to big cores. The tasklibrary then generates a heavy
load less than the number of big cores to ensure that the heavy tasks stay
within big cores. Reason being, It might spill over to LITTLE cores due to
Global Load Balancing Behaviour.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The low load is going to the LITTLE core only and that the heavy tasks are
staying within big cores.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>Since the background tasks on an android system cannot be controlled, this test
could fail intermittently if a background android task is hogging the big CPU
and forcing the <em>heavy</em> task to end up in the LITTLE CPU.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_FT0000">3.1.2. "FT0000" Test Case</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This test suite has the aim to assert that the scheduler has big.LITTLE MP support</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This test case checks if the big.LITTLE MP scheduling support for the ARM architecture is
available in the target kernel.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The scheduler has big.LITTLE MP Support.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_FT0001">3.1.3. "FT0001" Test Case</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This test suite has the aim to assert that the scheduler has a CPU-level domain
covering all CPUs.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>The scheduler <code>SCHED_HMP</code> requires the different CPU types to be represented by
an ordered list of hmp_domains. Each hmp_domain represents all CPUs of a
particular type using a cpumask. The list of CPUs and their domain information
is specific to a particular platform and hence is generated by scheduler
platform code. The scheduler initializes the HMP Domains,  and must be ordered
with respect to compute capacity, with the fastest domain at head of list.</p>
</div>
<div class="paragraph">
<p>The CPU list and domain information is obtained from the sys interface.
The CPU is parsed through for the available domains. There has to be a
CPU-Level domain for all the CPUs available.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The scheduler has a CPU-level domain for all the CPUs.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_FT0002">3.1.4. "FT0002" Test Case</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This test suite has the aim to assert that the scheduler has a CPU-level domain
with load balancing turned off.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>To provide a way for user to dynamically change the behaviour of load balance,
<code>SD_LOAD_BALANCE</code> flags of scheduler domain are set/unset. The scheduler
initially has the flag set to <em>0</em> such that the Load Balancing feature is
turned off.</p>
</div>
<div class="paragraph">
<p>This is checked by <code>/proc/sys/kernel/sched_domain/cpu#/domain#/flags</code>
dynamically. It tests if the scheduler is initially assigned a 1 to
<code>SD_LOAD_BALANCE</code> flag of the domain in the CPU list.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The scheduler has at least one domain with load balancing feature turned off.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<img src="./images/icons/note.png" alt="Note">
</td>
<td class="content">
load balancing at the CPU level is turned off since it is replaced by the
      big/little task classification. The big.LITTLE MP scheduler extensions will handle moving
      tasks among the two clusters based on their tracked load.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This could fail if the platform has not been initialized with the load balance
off for atleast one of its domains.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_FT0003">3.1.5. "FT0003" Test Case</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This test suite has the aim to assert that the scheduler has a package level
(MC) domain covering the reported siblings for each CPU.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>The scheduler has an MC domain. There are several default configurations of the
MC domain. For example, this default MC level configuration sets the
<code>SD_SHARE_PKG_RESOURCES</code> flag to mark the sharing of resources like the cache
between groups.</p>
</div>
<div class="paragraph">
<p>The CPU# sched domain (MC) covers the CPU list obtained by querying the debug
interface. The CPU siblings for the CPU# are listed using
/sys/devices/system/cpu/cpu#/topology/core_siblings</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>That the scheduler has a MC level domain covering the reported siblings for
each CPU.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_FT0004">3.1.6. "FT0004" Test Case</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This test suite has the aim of asserting that the scheduler has load balancing
turned on at the package level (MC) domains.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>The load balancing is used to ensure that no CPU is overloaded while others are
idle or that there is no obvious imbalance between running cpus. This check is
effectively done between groups at each sched_domain level that has the
<code>SD_LOAD_BALANCE</code> flag on.</p>
</div>
<div class="paragraph">
<p>The CPU List of the sched domain are listed initially through sysfs interface.
For each MC level domain, it is checked whether the load balancing is turned on
in the printable sched flags.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The scheduler  has load balancing turned on at the package level (MC) domains.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_FT0007">3.1.7. "FT0007" Test Case</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This test suite asserts that the test framework&#8217;s calculation of <em>fast</em> CPUs
are all A15s  as available from the platform. In case of TC2 it is A15s.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>The big CPUs are calculated by getting the CPU list through <code>/proc/cpuinfo</code>. The
CPU siblings lists is also populated for each CPU. The big CPU list is got
through the A15 core ID match from the above list. If any of the big CPUs are
differing in their IDs then the test fails.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>If all the CPUs in the populated lists are same as the ID given in the FT0007
test suite, then, the test goes to the passed state.</p>
</div>
</div>
<div class="sect3">
<h4 id="__ft0008_test_case">3.1.8. "FT0008" Test Case</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This test suite has the aim to Assert that all CPUs in the package domain for
<em>fast</em> CPUs are big CPUs.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>All big CPUs take part in a sched domain populated entirely by other big CPUs.
The Big CPUs calculated by getting the CPU list through <code>/proc/cpuinfo</code>. The Big
CPU list is got through the Big core ID match from the above list. The CPU
Sched domain list is also populated. This list is got by <code>/proc/schedstat</code> and
the bitfields/cpumask of the the CPUs covering this domain is populated in the
list. The big CPUs in the same domain are all fast CPUs.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>All the big CPUs in the populated lists are same as the list in the sched
domain list.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_FT0011">3.1.9. "FT0011" Test Case</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Assert that the test framework&#8217;s calculation of slow CPUs contains only A7
cores those cores considered as part of LITTLE cluster in the platform. For TC2
this is A7 cores.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>The LITTLE CPUs calculated by getting the CPU list through <code>/proc/cpuinfo</code>. The
CPU siblings lists is also populated for each CPU. The LITTLE CPU list is
obtained through the A7 core ID match from the above list. If any of the LITTLE
CPUs differ in their IDs then the test fails.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>If all the CPUs in the populated lists are same as the ID given in the FT0011
test suite, then, the test goes to the passed state.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_FT0012">3.1.10. "FT0012" Test Case</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This test suite has the aim to Assert that all CPUs in the package domain for
<em>slow</em> CPUs are LITTLE CPUs.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>All LITTLE CPUs take part in a sched domain populated entirely by other LITTLE
CPUs. The LITTLE CPUs calculated by getting the CPU list through
<code>/proc/cpuinfo</code>. The LITTLE CPU list is got through the LITTLE core ID match
from the above list. The CPU Sched domain list is also populated. This list is
got by <code>/proc/schedstat</code> and the bitfields/cpumask of the the CPUs covering
this domain is populated in the list. The LITTLE CPUs in the same domain are
all LITTLE CPUs.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>All the LITTLE CPUs in the populated lists are same as the list in the sched
domain list for Slow CPUs.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_FT0013">3.1.11. "FT0013" Test Case</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>The aim is to assert that the scheduler no longer prints fast/slow CPUs during
boot.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>The assertion is that the scheduler is not printing CPU indication in the boot
log. The big.LITTLE MP scheduler extensions used to print this info in the boot
log, but does not do this any longer.
1. Get the big CPU list in the bootlog.
2. Get the LITTLE CPU list in the bootlog.
3. Combine both the results
If the results show that there is big LITTLE CPU list present in the boot log,
then the test is passed else the test fails.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The results show that there is no big LITTLE CPU list info present in the Boot
log.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="suite_core">3.2. "Core" Test Suite</h3>
<div class="paragraph">
<p>This test suite has the aim to validate the basic functional behaviors of the
big.LITTLE MP scheduler extensions.</p>
</div>
<div class="paragraph">
<p>The intent of the test design is to generate synthetic tasks with specific load
characteristics, defined over a configured set of time points, and observe the
migration pattern across CPU domains based on events reported by the FTrace
kernel tracer.</p>
</div>
<div class="paragraph">
<p>The test cases allow specification of a discard period, which is ignored by the
ftrace analyser,  to avoid considering any task migration that might happen at
the beginning of the test case execution.</p>
</div>
<div class="paragraph">
<p>Following is the list of supported tests.</p>
</div>
<div class="sect3">
<h4 id="test_core_test_scn01.1">3.2.1. core_test_scn01.1</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Verify up migration of a task once it generates an increased CPU demand</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This test starts with a light task running on the LITTLE domain which is then
subject to a increase of load demand. The expected behavior is that the
big.LITTLE MP scheduler extensions move the task to a CPU of the big domain as
soon as the tracked task load becomes bigger than the configured <strong>up_migration</strong>
threshold.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behavior is reported in the following figure:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="images/core/core_test_scn01.1.png" alt="core test scn01.1">
</div>
<div class="title">Figure 1. LITTLE CPUs: (0-3), big CPUs: (4-7)</div>
</div>
<div class="paragraph">
<p>The tasklibrary-24034 task generates initially a low load till the
<span class="green">green marker</span>.  After that time point its execution pattern changes to
be a CPU bound with almost no idle periods. As the runnable time is longer
than idle time, the tracked task load increases over time as reported by the
<code>ratio</code> metrics of the <code>sched_task_runnable_ratio</code> events.</p>
</div>
<div class="paragraph">
<p>At the time of the <span class="red">red marker</span> the measured task load is 729, which is
higher than the 700 <strong>up_migration</strong> threshold configured on this test.
At that point the big.LITTLE MP scheduler extensions trigger a "forced
migration" (force=1) to move the now high demanding task to a CPU of the big
domain (CPU7 in this case).  Roughly ~50ms have been required to build up a
running ratio suitable to trigger an up migration.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<img src="./images/icons/note.png" alt="Note">
</td>
<td class="content">
a timeout is defined by this experiment to specify the maximum time
      considered acceptable for the task to be migrated.
      By default the migration time is expected to happen between
      1.7 and 2.2 [s] since the start of the experiment.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>The main reasons for this test to fails could be:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>up_migration</strong> threshold configured to be 1024
in this case the task will never be up-migrated since the maximum load a task
could build is capped to 1023.</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="test_core_test_scn02.1">3.2.2. core_test_scn02.1</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Verify down migration of a task once it generates a decreased CPU demand</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This test starts with a heavy task running on the big domain which is then
subject to a decrease of its load demand. The expected behavior is that the
big.LITTLE MP scheduler extensions move the task to a CPU of the LITTLE domain as soon as the
tracked task load goes below the configured <strong>down_migration</strong> threshold.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behavior is reported in the following figure:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="images/core/core_test_scn02.1.png" alt="core test scn02.1">
</div>
<div class="title">Figure 2. LITTLE CPUs: (0-4), big CPUs: (4-7)</div>
</div>
<div class="paragraph">
<p>The tasklibrary-23869 task generates initially a big load till the
<span class="green">green marker</span>.  After that time point its execution pattern changes to
show period bursts interleaved by long idle periods. Being idle time longer
than busy time, the tracked task load decreases over time as reported by the
ratio metrics of the sched_task_runnable_ratio events.</p>
</div>
<div class="paragraph">
<p>At the time of the <span class="red">red marker</span> the measured task load is 238, which is
lower than the 250 <strong>down_migration</strong> threshold configured on this test.
At that point the big.LITTLE MP scheduler extensions force a "wakeup migration"
(force=0) to move the now low demanding task to a CPU of the LITTLE domain
(CPU1 in this case).</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>The main reasons for this test to fails could be:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>down_migration threshold configured to be 0
in this case the task will never</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="test_core_test_scn03.1a">3.2.3. core_test_scn03.1a</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This starts with a heavy task on big domain, however the task priority is
modified mid way through execution below cutoff but no migration happens. The
task gets the CPU immediately.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This test asserts a priority threshold which prevents low priority task from
migrating. This is useful for user-space software which assigns lower task
priority to background task. <code>SCHED_HMP_PRIO_FILTER</code> enables task priority
based HMP migration filter. Since its of a lower priority, the task does not
migrate. Priority Cut-off value is one of the tunable conditions of the
scheduler for the task to migrate.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behaviour</div>
<p>The expected behavior is reported in the following figure:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="images/core/core_test_scn03.1a.png" alt="core test scn03.1a">
</div>
<div class="title">Figure 3. LITTLE CPUs: (0-3), big CPUs: (4-7)</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The task library generates heavy load in the beginning. Initial CPU
assignment is on big domain without any particular CPU affinity and with
priority &gt; cut-off priority</p>
</li>
<li>
<p>It is assumed that, Idle CPU is available in the cluster</p>
</li>
<li>
<p>Mid way through the execution of the load, priority of the task
is given  &lt; cutoff priority</p>
</li>
<li>
<p>No migration happens because of the task priority irrelavance in case of
down migration.</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>The main reasons for this test to fail could be:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>priority filter is disabled</p>
</li>
<li>
<p>cut-off priority is not configured</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="test_core_test_scn03.2a">3.2.4. core_test_scn03.2a</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This starts with a heavy task however the task priority is modified mid way
through execution below cutoff. Since the big domain is oversubscribed, the
task stays on LITTLE domain</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This test asserts a priority threshold which prevents low priority task from
migrating. This is useful for user-space software which assigns lower task
priority to background task. <code>SCHED_HMP_PRIO_FILTER</code> enables task priority
based HMP migration filter. When the task priority is modified, the task stays
on big domain.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behaviour</div>
<p>The expected behavior is reported in the following figure:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="images/core/core_test_scn03.2a.png" alt="core test scn03.2a">
</div>
<div class="title">Figure 4. LITTLE CPUs: (0-3), big CPUs: (4-7)</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The task library generates heavy load in the beginning. Initial CPU
assignment is on big domain without any particular CPU affinity and with
task priority &gt; cut-off priority</p>
</li>
<li>
<p>It is assumed that an Idle CPU is <strong>not</strong> available in the big cluster</p>
</li>
<li>
<p>Mid way through the execution of the load, priority of the task is changed
&lt; cutoff priority</p>
</li>
<li>
<p>No migration happens asserting the relevance of the priority</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>The main reasons for this test to fail could be:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>priority Filter is disabled</p>
</li>
<li>
<p>cut-off priority is not configured</p>
</li>
</ol>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<img src="./images/icons/warning.png" alt="Warning">
</td>
<td class="content">
This test is known to be likely to fail. In these cases, a visual
inspection of the collected trace could be required to verify that the
scheduler behavior is the expected one. The "expected behavior" is the one
reported in the previous figure.
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="test_core_test_scn4.1a">3.2.5. core_test_scn4.1a</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Verify CPU affinity enforcing on big tasks</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This test starts with a heavy task without any specific CPU affinity defined.
Being an high CPU load demanding task, it is expected to be running from the
beginning on a CPU of the big domain.</p>
</div>
<div class="paragraph">
<p>The CPU affinity mask of this task is modified mid way through execution to
allows its execution just on CPUs of the LITTLE domain. This is expected to
force an immediate migration of the task on a CPU of the LITTLE domain.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behavior is reported in the following figure:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="images/core/core_test_scn04.1.png" alt="core test scn04.1">
</div>
<div class="title">Figure 5. LITTLE CPUs: (0-3), big CPUs: (4-7)</div>
</div>
<div class="paragraph">
<p>The tasklibrary-5321 task generates an high load and therefore it runs on CPUs
of the big domain, in this example run it starts on CPU4 and then move to CPU5.
This is the expected behavior since before the <span class="green">green marker</span> the task
has not a specific CPU affinity mask.</p>
</div>
<div class="paragraph">
<p>At the time of the <span class="green">green marker</span>, the task affinity is forced to be the
CPUs of the LITTLE domain only, at that point the scheduler forces a migration
<code>sched_migrate_task</code> to a CPU of the LITTLE domain even though the task runnable
ratio remains over the <strong>up_migration</strong> threshold.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is expected not to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_core_test_scn4.2">3.2.6. core_test_scn4.2</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Verify CPU affinity enforcing on small tasks</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This test starts with a small task without any specific CPU affinity defined.
Being a small CPU load demanding task, it is expected to be running on
a CPU of the LITTLE domain.</p>
</div>
<div class="paragraph">
<p>The CPU affinity mask of this task is modified mid way through execution to
allows its execution just on CPUs of the big domain. This is expected to
force an enqueuing of the task on a CPU of the big domain, as soon as the task
becomes runnable.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behavior is reported in the following figure:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="images/core/core_test_scn04.2.png" alt="core test scn04.2">
</div>
<div class="title">Figure 6. LITTLE CPUs: (0-3), big CPUs: (4-7)</div>
</div>
<div class="paragraph">
<p>Generally, new tasks are created on CPUs of the big domain to boost
performance of potentially high load demanding tasks. This is the reason why
the tasklibrary-5415 task starts its execution on CPU5 in this example.
However, as it is a small task and as it is not affinitised to a specific CPU,
as expected, pretty soon after start, precisely at the time of
shown by the <span class="green">green marker</span>, it is moved to run on CPU2 of
the LITTLE domain.</p>
</div>
<div class="paragraph">
<p>At the time of the <span class="red">red marker</span>, the task affinity is set to include
only the CPUs of the big domain. Thus, after that point, the first time the
scheduler has the opportunity to decide where to schedule this task, it is
moved into a CPU of the big domain. Being it a small load task, which runs for
short bursts and sleeps longer, in this case, the first opportunity for
migration if the first <code>sched_wakeup</code> right after the time the affinity mask
has been updated.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is expected not to fail.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="suite_extended">3.3. "Extended" Test Suite</h3>
<div class="paragraph">
<div class="title">Goal</div>
<p>The primary aim of the test cases within extended_suite is to validate some of
the boundary conditions related to the functional behaviour of the big.LITTLE
MP scheduler extensions.</p>
</div>
<div class="paragraph">
<p>To start the execution of just this test:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-run extended</code></pre>
</div>
</div>
<div class="paragraph">
<p>Following is the list of supported tests</p>
</div>
<div class="sect3">
<h4 id="test_extd_test_scn01.1">3.3.1. extd_test_scn01.1</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Verify <strong>down-threshold</strong> value of a task once it is generating a decreased CPU
demand</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This scenario assumes the heavy task is already in big domain, however its
computed load is decreasing due to the load pattern (due to idling).The
expected behaviour is that the task stays in big domain since the task load has
not yet crossed below the down-threshold.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behavior is reported in the following figure:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="images/extended/extd_test_scn01.1.png" alt="extd test scn01.1">
</div>
</div>
<div class="paragraph">
<p>The tasklibrary task generates initially a big load till the
<span class="purple">purplemarker</span>.  After that time point its execution pattern changes to
show period bursts interleaved by long idle periods. Being idle time longer
than busy time, the tracked task load decreases over time as reported by the
ratio metrics of the sched_task_runnable_ratio events.</p>
</div>
<div class="paragraph">
<p>At the time of the <span class="green">green marker</span> the task load is not lower than
<strong>down_migration</strong> threshold configured on this test. Load is 473 where as the
threshold is 256. At that point the big.LITTLE MP scheduler extensions <strong>do not</strong>
force a "wakeup migration" to move the now low demanding task to a CPU of the
LITTLE domain.</p>
</div>
<div class="olist arabic">
<div class="title">Possible Issues</div>
<ol class="arabic">
<li>
<p>Down migration threshold is configured to 0</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="test_extd_test_scn01.2a">3.3.2. extd_test_scn01.2a</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Verify down migration of a task once the big domain is over subscribed</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This test starts with a heavy task running on the Big
domain which is then subject to a increase of its load demand. But since no
Idle CPU is available and the big Domain is oversubscribed, the The expected
behavior is that the big.LITTLE MP scheduler extensions move the task to a CPU
of the LITTLE domain.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behavior is reported in the following figure:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="images/extended/extd_test_scn01.2a.png" alt="extd test scn01.2a">
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The task library generates initially a heavy load starting on big domain</p>
</li>
<li>
<p>The CPU affinity is not set at this point. The priority of the task is &lt;
cut-off priority</p>
</li>
<li>
<p>The task gears up more load but the Big domain is over subscribed</p>
</li>
<li>
<p>Hence a forced task migration happens moving the heavy task to a CPU of the
LITTLE domain</p>
</li>
</ol>
</div>
<div class="olist arabic">
<div class="title">Possible Issues</div>
<ol class="arabic">
<li>
<p>Idle CPU being available at the point of migration</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="test_extd_test_scn01.4">3.3.3. extd_test_scn01.4</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Verify <strong>up-threshold</strong> value of a task once it is generating an increased CPU
demand</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This scenario assumes the light task is already in LITTLE domain, however its
computed load is increasing due to the load pattern (due to run queue
residency).The expected behaviour is that the task stays in LITTLE domain since
the task load has not yet crossed above the up-threshold.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behavior is reported in the following figure:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="images/extended/extd_test_scn01.4.png" alt="extd test scn01.4">
</div>
</div>
<div class="paragraph">
<p>The tasklibrary task generates initially a light load till the <span class="purple">purple
marker</span>.  After that time point its execution pattern changes. The CPU demand
is increased, The tracked task load increases over time.</p>
</div>
<div class="paragraph">
<p>At the time of the <span class="green">green marker</span> the task load (495) is not greater
than  <strong>up_migration</strong> threshold (700) configured on this test. At that point the
big.LITTLE MP scheduler extensions <strong>do not</strong> force a "wakeup migration" to move
the now low demanding task to a CPU of the Big domain.</p>
</div>
<div class="olist arabic">
<div class="title">Possible Issues</div>
<ol class="arabic">
<li>
<p>Up migration threshold is configured to 0</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="test_extd_test_scn03.1">3.3.4. extd_test_scn03.1</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Verify <strong>down-threshold</strong> value of a task once it is generating a decreased CPU
demand</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This scenario assumes a heavy task is already in big domain, however its
computed load is decreasing due to the load pattern (due to idling).The
expected behaviour is that the task stays in big domain since the task load has
not yet crossed below the down-threshold.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behavior is reported in the following figure:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="images/extended/extd_test_scn03.1.png" alt="extd test scn03.1">
</div>
</div>
<div class="paragraph">
<p>The tasklibrary task generates initially a heavy load till the <span class="purple">purple
marker</span>.  After that time point its execution pattern changes. The CPU demand
is decreased, The tracked task load decreases over time.</p>
</div>
<div class="paragraph">
<p>At the time of the <span class="green">green marker</span> the task load (495) is not lesser than
<strong>down_migration</strong> threshold (256) configured on this test. At that point the
big.LITTLE MP scheduler extensions <strong>does not</strong> force a "wakeup migration" to
move the now low demanding task to a CPU of the LITTLE domain.</p>
</div>
<div class="olist arabic">
<div class="title">Possible Issues</div>
<ol class="arabic">
<li>
<p>Down migration threshold is configured to 0</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="test_extd_test_scn03.2a">3.3.5. extd_test_scn03.2a</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Verify down migration of a task once the big domain is over subscribed</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This test starts with a heavy task running on the Big domain which is then
subject to a decrease of its load, CPU demand. But since no Idle CPU is
available and the big Domain is oversubscribed, the expected behavior is that
the big.LITTLE MP scheduler extensions move the task to a CPU of the LITTLE
domain.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behavior is reported in the following figure:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="images/extended/extd_test_scn03.2a.png" alt="extd test scn03.2a">
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The task library generates initially a heavy load starting on big domain.</p>
</li>
<li>
<p>The CPU affinity is not set at this point. The priority of the task is
&lt; cut-off priority.</p>
</li>
<li>
<p>The task sheds down more load due to idling but the Big domain is
over subscribed.</p>
</li>
<li>
<p>Hence a forced task migration happens moving the now low
task to a CPU of the LITTLE domain.</p>
</li>
</ol>
</div>
<div class="olist arabic">
<div class="title">Possible Issues</div>
<ol class="arabic">
<li>
<p>idle CPU being available at the point of migration</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="test_extd_test_scn03.4">3.3.6. extd_test_scn03.4</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Verify that at the down threshold boundary condition, the migration does not
happen.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This scenario assumes the light task is already in LITTLE domain however its
computed load is increasing due to the load pattern (due to run queue
residency). The task stays in LITTLE domain eventhough the task load has
reached at the down-threshold. The runnable task gets the CPU immediately.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behavior is reported in the following figure:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="images/extended/extd_test_scn03.4.png" alt="extd test scn03.4">
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Initial task load is less than up threshold and equal to down threshold and
starts with LITTLE domain</p>
</li>
<li>
<p>The CPU affinity is left unspecified and the priority is greater than
cut-off priority</p>
</li>
<li>
<p>It is assumed that the idle CPU is available</p>
</li>
<li>
<p>Load increases but migration does not happen</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fails</p>
</div>
</div>
<div class="sect3">
<h4 id="test_extd_test_scn04.1">3.3.7. extd_test_scn04.1</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Verify that the CPU migration does not precede over CPU affinity during
boundary conditions.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This is a light task which started with Big domain due to CPU affinity and
despite migration criteria satisfied is continuing on Big domain. The task gets
CPU immediately.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behavior is reported in the following figure:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="images/extended/extd_test_scn04.1.png" alt="extd test scn04.1">
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Initial task load is less than up threshold and less than down threshold
and starts with Big domain</p>
</li>
<li>
<p>The CPU affinity is specified as Big domain and the priority is less than
cut-off priority</p>
</li>
<li>
<p>It is assumed that the idle CPU is available</p>
</li>
<li>
<p>Migration to LITTLE domain does not happen even though it is supposed to, as
the CPU affinity takes precedence over it</p>
</li>
</ol>
</div>
<div class="olist arabic">
<div class="title">Possible Issues</div>
<ol class="arabic">
<li>
<p>CPU affinity not specified</p>
</li>
<li>
<p>cut off priority not specified</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="test_extd_test_scn04.2">3.3.8. extd_test_scn04.2</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Verify that the CPU migration does not precede over CPU affinity during
boundary conditions.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This is a heavy task which started in big domain due to initial CPU affinity
being big cores, however despite due to the load pattern (being in idle) and
the computed task load is decreasing below the down threshold, the task
continues on Big domain due to CPU affinity. The task gets the CPU immediately.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behavior is reported in the following figure:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="images/extended/extd_test_scn04.2.png" alt="extd test scn04.2">
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Initial task load is less than up threshold and less than down threshold and
starts with Big domain</p>
</li>
<li>
<p>The CPU affinity is specified as Big domain B0, or B1 and the priority is
less than cut-off priority</p>
</li>
<li>
<p>It is assumed that the idle CPU is available</p>
</li>
<li>
<p>Migration to LITTLE domain does not happen even though it is supposed to, as
the CPU affinity takes precedence over it</p>
</li>
</ol>
</div>
<div class="olist arabic">
<div class="title">Possible Issues</div>
<ol class="arabic">
<li>
<p>CPU affinity not specified</p>
</li>
<li>
<p>cut off priority not specified</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="suite_hwbreakpoint">3.4. "HwBreakpoint" Test Suite</h3>
<div class="paragraph">
<div class="title">Goal</div>
<p>The primary aim of the test cases within hwbreakpoint_suite is to validate
ability of hardware breakpoints to survive power down sequences in a big.LITTLE
system.</p>
</div>
<div class="paragraph">
<p>To start the execution of just this test:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-run hwbreakpoint</code></pre>
</div>
</div>
<div class="paragraph">
<p>Following is the list of supported tests</p>
</div>
<div class="sect3">
<h4 id="test_hwbp_test_01">3.4.1. hwbp_test_01</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This tests that using hw breakpoints over powerdown is possible.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This test checks if the hardware breakpoint can be applied to tasks. The test
makes use of the taskset library to get the CPU mask and adds hardware
breakpoint/watchpoint support for the arm-linux-gnueabi target to gdbserver
through breakpoint_test program.</p>
</div>
<div class="paragraph">
<p>A process is forked to form parent and child.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The child program launches tests which sets up break point traps in Dummy
Functions and waits for the signal SIGTRAP which comes from the gdb. Once
this comes, it enables a memory in the main program and exits.</p>
</li>
<li>
<p>The parent tests if the test id launched and tests if the traps are set. It
calls the Dummy functions where dummy functions were set. If the Memory in
the main program is enabled, results are sent as passed.</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected result is that hardware breakpoints is supported</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="suite_irqs">3.5. "IRQs" Test Suite</h3>
<div class="paragraph">
<div class="title">Goals</div>
<p>All pinnable IRQs are expected to be served just by LITTLE CPUs to reduce
at minimum the wakeup of energy inefficient CPUs in the big cluster.
This test aims at vertify the configuration of IRQ affinities on the target
platform.</p>
</div>
<div class="paragraph">
<p>A new test will be added to check for:
2. each and every registered IRQ and reports those that uses big
   CPUs in their affinity mask.
   This is just to allows a cross-checking that some pinnable IRQ has
   not been properly configured to be pinned on LITTLE cpus.</p>
</div>
<div class="paragraph">
<p>To start the execution of just this test:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-run irqs</code></pre>
</div>
</div>
<div class="paragraph">
<p>Following is the list of supported tests</p>
</div>
<div class="sect3">
<h4 id="test_00_default_affinity">3.5.1. 00_default_affinity</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Assert that the default affinity of each IRQ is pinned on LITTLE CPUs</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>The procfs attribute <code>/proc/irq/default_smp_affinity</code> specifies default
affinity mask that applies to all non-active IRQs.
Once IRQ is allocated/activated its affinity bitmask will be set to the default
mask.
Thus, this mask is of paramount importance to ensure that all IRQ handlers
registered at run-time (e.g. module load time) are possibly served only by
energy efficient LITTLE cpus.</p>
</div>
<div class="paragraph">
<p>Reference documentation:
<a href="http://lxr.free-electrons.com/source/Documentation/IRQ-affinity.txt" class="bare">http://lxr.free-electrons.com/source/Documentation/IRQ-affinity.txt</a></p>
</div>
<div class="paragraph">
<p>The default IRQ affinity mask is checked by this test and used and warn the
user in case of big CPUs not being excluded.
On a big.LITTLE system this is the recommended configuration.</p>
</div>
<div class="olist arabic">
<div class="title">Possible issues</div>
<ol class="arabic">
<li>
<p>the affinity mask has not been tuned at system boot</p>
</li>
<li>
<p>the IRQ controller does not support IRQ affinity</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="test_01_irqs_on_bigs">3.5.2. 01_irqs_on_bigs</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Report all the IRQs which are pinned on CPUs of the big cluster.</p>
</div>
<div class="paragraph">
<div class="title">Detailed description</div>
<p>Despite the general recommendation for big.LITTLE systems to have all the IRQs
pinned just on LITTLE CPUs, there could be some IRQs source which must be
targeted to specific CPUs.</p>
</div>
<div class="paragraph">
<p>The <code>procfs</code> attributes <code>/proc/irq/IRQ#/smp_affinity</code> specify which target CPUs
are permitted for a given IRQ source.  It&#8217;s a bitmask (smp_affinity) of allowed
CPUs.  It&#8217;s not allowed to turn off all CPUs, and if an IRQ controller does not
support IRQ affinity then the value will not change from the default of all
cpus.</p>
</div>
<div class="paragraph">
<p>Reference documentation:
<a href="http://lxr.free-electrons.com/source/Documentation/IRQ-affinity.txt" class="bare">http://lxr.free-electrons.com/source/Documentation/IRQ-affinity.txt</a></p>
</div>
<div class="paragraph">
<p>This test checks and report all the IRQ sources which are currently configured
to run on big CPUs. The test <span class="red">FAILS</span> if at least one source is routed on
big CPUs.  However: it is responsibility of the user to identify it these IRQs
sources must be mandatory routed on a big CPU and in that case the test could
be considered as being <span class="green">PASSED</span></p>
</div>
<div class="olist arabic">
<div class="title">Possible issues</div>
<ol class="arabic">
<li>
<p>some IRQ sources must be targeted on big CPUs</p>
</li>
<li>
<p>the IRQ controller does not support IRQ affinity</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="suite_loadbalance">3.6. "Load Balance" Test Suite</h3>
<div class="paragraph">
<div class="title">Goal</div>
<p>The primary aim of the test cases within loadbalance_suite is to validate
global load balancing behaviour of the scheduler across CPU domains in a
big.LITTLE system.</p>
</div>
<div class="paragraph">
<p>To start the execution of just this test:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-run loadbalance</code></pre>
</div>
</div>
<div class="paragraph">
<p>Following is the list of supported tests</p>
</div>
<div class="sect3">
<h4 id="test_lb_scn_00">3.6.1. lb_scn_00</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is to assert about the Performance improvement of the system because of
global load balancing behaviour of the scheduler.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This scenario does two multi-threaded runs of sysbench: One with affinity set
to the fast cpus, and one with default affinity (all).A performance improvement
is expected in the second case as the scheduler can use the slower CPUs as
well.</p>
</div>
<div class="paragraph">
<p>This test asserts that a periodic balance check that can down-migrate tasks if
the faster domain is oversubscribed and the slower is under-utilized when there
is no CPU affinity specified.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>A performance improvement is expected as the scheduler can use the slower cpus
as well.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_lb_scn_01">3.6.2. lb_scn_01</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is to assert about the Performance improvement of the system because of
global load balancing behaviour of the scheduler.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This scenario does two simultaneous multi-threaded runs of sysbench. The
expectation is that the scheduler will use all CPUs when there is more load
than the big CPUs can handle and as the threads finishes the remaining threads
will be migrated to the big CPUs to get best possible performance.</p>
</div>
<div class="paragraph">
<p>It is assumed that the number of LITTLE CPUs &gt;= number of big cpus</p>
</div>
<div class="paragraph">
<p>This test asserts that a periodic balance check that can down-migrate tasks if
the faster domain is oversubscribed and the slower is under-utilized when there
is no CPU affinity specified.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>A performance improvement is expected as the scheduler can use the slower cpus
as well.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="suite_non_functional_suite">3.7. "Non Functional" Test Suite</h3>
<div class="paragraph">
<div class="title">Goal</div>
<p>The primary aim of the test cases within non_functional_suite is to validate
the big.LITTLE MP capable kernel&#8217;s ability to perform in stress scenarios and
to assess platform stability with the big.LITTLE MP scheduler extensions being
active.</p>
</div>
<div class="paragraph">
<p>To start the execution of just this test:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-run non_functional</code></pre>
</div>
</div>
<div class="paragraph">
<p>Following is the list of supported tests</p>
</div>
<div class="sect3">
<h4 id="test_stability_test_scn03.1">3.7.1. stability_test_scn03.1</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is a stability test to check if all the big.LITTLE MP scheduler extensions
have been integrated fully and properly.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>Create a large task pool for HMP migration and check if the kernel is passing
the stability test without crashing. The following are done to create large
task pool for HMP migration and test the kernel.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>For observation of results, save a snapshot of process info from <code>/proc</code>
filesystem.</p>
</li>
<li>
<p>Using synthetic task library, generate 100 <em>heavy</em> tasks, with
varying nice values. Due to Global Balancing behaviour, both Big and Little
domains are fully utilized.</p>
</li>
<li>
<p>Wait for all the task library to be completed.
For observation, save a snapshot of process info from <code>/proc</code> filesystem.</p>
</li>
<li>
<p>Confirm if the kernel is still functional, then test is PASSED.</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>After the stability test of more than 10 hours, kernel
should still be functional.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_stability_test_scn04.1">3.7.2. stability_test_scn04.1</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is a stability test to check if all the big.LITTLE MP scheduler extensions
have been integrated fully and properly.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>Create a large task pool for HMP migration and Hot unplug cores from either
domains to check if the kernel is passing the stability test without
crashing.The following are done to create large task pool for HMP migration and
test the kernel.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>For observation of results, save a snapshot of process info from <code>/proc</code>
filesystem.</p>
</li>
<li>
<p>Using synthetic task library, generate 100 <em>heavy</em> tasks, with varying nice
values. Due to Global Balancing behaviour, both Big and Little domains are
fully utilized.</p>
</li>
<li>
<p>Hot unplug one core each from both the big and LITTLE domains, the reduced
core does not affect HMP migration operations.</p>
</li>
<li>
<p>Wait for all the task library to be completed. For observation, save a
snapshot of process info from <code>/proc</code> filesystem.</p>
</li>
<li>
<p>Confirm if the kernel is still functional, then test is PASSED.</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>After the stability test of more than 10 hours, kernel should still be
functional.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_stability_test_scn04.2">3.7.3. stability_test_scn04.2</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is a stability test to check if all the big.LITTLE MP scheduler extensions
have been integrated fully and properly.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>Create a large task pool for HMP migration and Hot unplug all big cores from
either domains to check if the kernel is passing the stability test without
crashing.The following are done to create large task pool for HMP migration and
test the kernel.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>For observation of results, save a snapshot of process info from <code>/proc</code>
filesystem.</p>
</li>
<li>
<p>Using synthetic task library, generate 100 <em>heavy</em> tasks, with varying nice
values. Due to Global Balancing behaviour, both Big and Little domains are
fully utilized.</p>
</li>
<li>
<p>Hot unplug all 2 big cores from the big domain, the reduced core
does not affect HMP migration operations.</p>
</li>
<li>
<p>Wait for all the task library to be completed. For observation, save a
snapshot of process info from <code>/proc</code> filesystem.</p>
</li>
<li>
<p>Confirm if the kernel is still functional, then test is PASSED.</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>After the stability test of more than 10 hours, kernel should still be
functional.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_stability_test_scn05.1">3.7.4. stability_test_scn05.1</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is a stability test to check if all the big.LITTLE MP scheduler extensions
have been integrated fully and properly.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>Idle for a long period of time and check if the kernel is passing the stability
test without crashing.The following are done to test the kernel.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>For observation of results, save a snapshot of process info from <code>/proc</code>
filesystem.</p>
</li>
<li>
<p>Let the system idle for set duration (large duration). The Idle code path
should be executed without any panic.</p>
</li>
<li>
<p>Wait for idle amount time to be completed. For observation, save a snapshot
of process info from <code>/proc</code> filesystem.</p>
</li>
<li>
<p>Confirm if the kernel is still functional, then test is PASSED.</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>After the stability test of more than 10 hours, kernel should still be
functional.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_stability_test_scn06.1">3.7.5. stability_test_scn06.1</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is a stability test to check if all the big.LITTLE MP scheduler extensions
have been integrated fully and properly.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>Idle for a repeated number of times and check if the kernel is passing the
stability test without crashing.The following are done to test the kernel.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>For observation of results, save a snapshot of process info from <code>/proc</code>
filesystem.</p>
</li>
<li>
<p>Run busy loop for a set duration.This path should be executed
without any panic.</p>
</li>
<li>
<p>Let the system idle for set duration. The Idle code path should be executed
without any panic. Repeat 2 and 3 for n number of times.</p>
</li>
<li>
<p>Wait for idle/busy time to be completed. For observation, save a snapshot of
process info from <code>/proc</code> filesystem.</p>
</li>
<li>
<p>Confirm if the kernel is still functional, then test is PASSED.</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>After the stability test of more than 10 hours, kernel should still be
functional.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_stress_test_scn01.1">3.7.6. stress_test_scn01.1</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is a stress test to check if all the big.LITTLE MP scheduler extensions
have been integrated fully and properly.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>Create a large task pool for HMP migration and check if the kernel is passing
the stability test without crashing. The following are done to create large
task pool for HMP migration and test the kernel.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>For observation of results, save a snapshot of process info from <code>/proc</code>
filesystem.</p>
</li>
<li>
<p>Using synthetic task library, generate 100 <em>heavy</em> tasks, with varying nice
values. Due to Global Balancing behaviour, both Big and Little domains are
fully utilized.</p>
</li>
<li>
<p>Wait for all the task library to be completed.  For observation, save a
snapshot of process info from <code>/proc</code> filesystem.</p>
</li>
<li>
<p>Confirm if the kernel is still functional, then test is PASSED.</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>After the stability test of more than 10 hours, kernel should still be
functional.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="suite_pmu">3.8. "PMU" Test Suite</h3>
<div class="paragraph">
<div class="title">Goal</div>
<p>The primary aim of the test cases within pmu_suite is to validate PMU support
for a big.LITTLE system.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<img src="./images/icons/note.png" alt="Note">
</td>
<td class="content">
The description of this suite uses as a reference a TC2 board, with a
2big-3LITTLE topology.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To start the execution of just this test:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-run pmu</code></pre>
</div>
</div>
<div class="paragraph">
<p>Following is the list of supported tests</p>
</div>
<div class="sect3">
<h4 id="test_pmu_test_scn01">3.8.1. pmu_test_scn01</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>The aim of this test is to validate the correct event counting on a per-process
basis in MP configuration where the task is forced to migrate across clusters
multiple times.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>The task characteristic would be with more CPU intensive operations to force
the CPU cycle counting and instruction counting, including some idle time.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The cycles program is set for per process counting for counting CPU cycles
and instructions.</p>
</li>
<li>
<p>Perf is calculated for the non-grouped user mode events occured</p>
</li>
<li>
<p>Confirm if the CPU cycles and instructions generated are matching
with the perf results.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The variants of this test case could be done where the scenarios with a single
task which is being monitored OR with multiple tasks where the runQ residency
of the monitored task is more.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected result is that the counters keep correct counting against the
monitored process, irrespective of the CPU where the monitored process is
migrated to across big/little clusters.</p>
</div>
<div class="olist arabic">
<div class="title">Possible Issues</div>
<ol class="arabic">
<li>
<p>perf might sometimes throw <em>too many open files</em> error</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="test_pmu_test_scn02">3.8.2. pmu_test_scn02</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>The aim of this test is to validate the correct event counting on a per-CPU
basis in MP configuration where the task is forced to migrate across clusters
multiple times.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>The task characteristic would be with more memory bound operations on buffers
larger than cache size to force cache miss scenarios and cache refresh.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The cache program is set for per CPU counting for counting cache references
and cache misses.</p>
</li>
<li>
<p>Perf is calculated for the events occured</p>
</li>
<li>
<p>Confirm if the Cache references and cache misses generated are matching with
the perf results.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The variants of this test case could be done where the scenarios would select
the CPU to be monitored either in Big or Little cluster.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected result is that the counters keep correct counting on the specific
CPU only, as long as a process is utilising that CPU.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail</p>
</div>
</div>
<div class="sect3">
<h4 id="test_pmu_test_scn03">3.8.3. pmu_test_scn03</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>The aim of this test is to validate the correct event counting on a system wide
basis across all CPUs in all available clusters in MP configuration, where the
task is forced to migrate across clusters multiple times.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>The task characteristic would be with more operations that switch between user
and kernel mode of operations and looping structures and function calls.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The branch program is set for per system counting for sample counting of
branch instructions and branch misses.</p>
</li>
<li>
<p>Perf is calculated for the grouped mode events occured</p>
</li>
<li>
<p>Confirm if the Branch instructions and misses generated are matching with
the perf results.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The variants of this test case could be done where the scenarios with a single
task which is being monitored OR with multiple tasks where the runQ residency
of the monitored task is more.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected result is that the counters keep correct counting across all the
CPUs in the systems.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail</p>
</div>
</div>
<div class="sect3">
<h4 id="test_pmu_test_scn04">3.8.4. pmu_test_scn04</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>The aim of this test is to validate the correct event counting on a ‘sub’
system wide basis across all CPUs within the defined sub system in MP
configuration, where the task is forced to migrate across clusters multiple
times.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>The task characteristic would be with more memory bound operations on buffers
larger than cache size to force cache miss scenarios and cache refresh.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The cache and cycles program is set for per sub system (3 LITTLE cores in
the LITTLE cluster) counting of cycles, cache references and misses counts.</p>
</li>
<li>
<p>Perf is calculated for the grouped mode events occured</p>
</li>
<li>
<p>Confirm if the cache references and misses generated are matching with the
perf results.</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected result is that the counters keep correct counting across all the
CPUs in the specified ‘sub’ systems.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail</p>
</div>
</div>
<div class="sect3">
<h4 id="test_pmu_test_scn05">3.8.5. pmu_test_scn05</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>The aim of the test is to test the negative scenario where the event count is
set above the available number of counters on the selected LITTLE cluster.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>If there are more events than counters, the kernel uses time multiplexing to
give each event a chance to access the monitoring hardware. Multiplexing only
applies to PMU events. With multiplexing, an event is not measured all the
time.  At the end of the run, the tool scales the count based on total time
enabled vs time running.</p>
</div>
<div class="paragraph">
<p>This provides an estimate of what the count would have been, had the event been
measured during the entire run. Depending on the workload, there will be blind
spots which can introduce errors during scaling.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The cache and cycles program is set for per sub system (3 LITTLE cores in
the LITTLE cluster) counting of cycles, cache references,cache misses,
branch misses and branch instruction counts.</p>
</li>
<li>
<p>Perf is calculated for the events occured</p>
</li>
<li>
<p>Confirm if the cache references and misses and branch instructions generated
are not matching with the perf results.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The variation to this test case can be whether the chosen counters are grouped
or not.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected result is event not supported when the number of events is more
than the available number of counters.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail</p>
</div>
</div>
<div class="sect3">
<h4 id="test_pmu_test_scn06">3.8.6. pmu_test_scn06</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>The aim of the test is to test the negative scenario where the event count is
set above the available number of counters on the selected big cluster.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>If there are more events than counters, the kernel uses time multiplexing to
give each event a chance to access the monitoring hardware. Multiplexing only
applies to PMU events. With multiplexing, an event is not measured all the
time.  At the end of the run, the tool scales the count based on total time
enabled vs time running.</p>
</div>
<div class="paragraph">
<p>This provides an estimate of what the count would have been, had the event been
measured during the entire run. Depending on the workload, there will be blind
spots which can introduce errors during scaling.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The cache and cycles program is set for per sub system (2 big cores in the
big cluster) counting of CPU cycles, instruction, cache references, cache
misses, branch instructions, branch misses, bus cycles.</p>
</li>
<li>
<p>Perf is calculated for the events occured</p>
</li>
<li>
<p>Confirm if the cache references and misses and branch instructions generated
are not matching with the perf results.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The variation to this test case can be whether the chosen counters are grouped
or not.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected result is event not supported when the number of events is more
than the available number of counters.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test case is not expected to fail</p>
</div>
</div>
<div class="sect3">
<h4 id="test_pmu_test_scn07">3.8.7. pmu_test_scn07</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>The aim of this test is to validate the correct event counting on a system wide
basis across all CPUs in all available clusters in MP configuration, where the
task is forced to migrate across clusters multiple times.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>The task characteristic would be with more operations that switch between user
and kernel mode of operations and looping structures and function calls. This
test expects CPU idle and CPU freq to be enabled in the kernel configuration.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The branch program is set for the system to count Branch instructions,
branch misses.</p>
</li>
<li>
<p>Exclude User Mode.</p>
</li>
<li>
<p>Perf is calculated for the grouped mode events occured</p>
</li>
<li>
<p>Confirm if the Branch instructions, branch misses generated
are matching with the perf results.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The variation to this test case can be whether the chosen counters are grouped
or not.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected result is that the counters keep correct counting across all the
CPUs in the systems.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail</p>
</div>
</div>
<div class="sect3">
<h4 id="test_pmu_test_scn08">3.8.8. pmu_test_scn08</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>The aim of this test is to validate the correct event counting on a system
wide basis across all CPUs in all available clusters in MP configuration, where
the task is forced to migrate across clusters multiple times.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>The task characteristic would be looping structures and function calls in non
idle modes.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The branch program is set for the system to count Branch instructions,
branch misses.</p>
</li>
<li>
<p>Perf is calculated for the grouped mode events occured</p>
</li>
<li>
<p>Idle mode is not included.</p>
</li>
<li>
<p>Confirm if the Branch instructions, branch misses generated are matching
with the perf results.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The variation to this test case can be whether the chosen counters are grouped
or not.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected result is that the counters keep correct counting across all the
CPUs in the systems.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fails.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_pmu_cci_test_scn09">3.8.9. pmu_cci_test_scn09</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>The aim of this test System wide counting for CCI events when test scenario is
run in MP mode.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This tests CCI PMU by running cache on LITTLE CPU and counting cacheable reads
and write evict transactions on the LITTLE CPU.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The cache program is set for the system to count Read request shareable
only, Read data from snoop, Read request stall -  address hazard</p>
</li>
<li>
<p>Perf is calculated for the grouped mode events occured</p>
</li>
<li>
<p>Confirm if the cache references, misses are matching with the perf results.</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected result is that the counters keep correct counting across all the
CPUs in the systems.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_pmu_cci_test_scn10">3.8.10. pmu_cci_test_scn10</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>The aim of this test System wide counting for CCI events when test scenario is
run in MP mode and the counters are grouped.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This tests CCI PMU by running cache on big CPU and counting cacheable reads and
write evict transactions on the big CPU.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The cache program is set for the system to count Read request - cache
maintenance, Write request any, Write request stall -  barrier hazard</p>
</li>
<li>
<p>Perf is calculated for the grouped mode events occured</p>
</li>
<li>
<p>Confirm if the cache references, misses are matching with the perf results.</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected result is that the counters keep correct counting across all the
CPUs in the systems.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_pmu_cci_test_scn11">3.8.11. pmu_cci_test_scn11</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>The aim of this is to test CCI PMU by running cache program on big CPUs and
counting events in sampling mode. This is done by not grouping the events and
specifying more events than counters. The testcase checks that the extrapolated
value returned is within range of the golden run.</p>
</div>
<div class="olist arabic">
<div class="title">Detailed Description</div>
<ol class="arabic">
<li>
<p>The cache program is set for the system to count Read request shareable
only, Read data from snoop, Read request cache maintenance, Write request
any, write request stall -  barrier hazard</p>
</li>
<li>
<p>Hotplug OFF the CPU</p>
</li>
<li>
<p>Perf is calculated for the events occured</p>
</li>
<li>
<p>Hotplug ON the CPU</p>
</li>
<li>
<p>Confirm if the cache read/write requests, cache maintainance, are matching
with the perf results</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected result is that the counters keep correct counting across all the
CPUs in the systems.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="suite_regression_suite">3.9. "Regression" Test Suite</h3>
<div class="paragraph">
<div class="title">Goal</div>
<p>The primary aim of the test cases within Regression suite is to validate
behaviour of vanilla scheduler / big.LITTLE MP scheduling extensions in a
big.LITTLE system.</p>
</div>
<div class="paragraph">
<p>To start the execution of just this test:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-run regression</code></pre>
</div>
</div>
<div class="paragraph">
<p>Following is the list of supported tests</p>
</div>
<div class="sect3">
<h4 id="test_affinity_notchanged">3.9.1. affinity_notchanged</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is to test the scheduler of any vulnerabilities which might be present
with or without big.LITTLE MP scheduler extensions.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>These tests are taken from LWN.net</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Switch to CPUn through <code>sched_setaffinity</code> call.</p>
</li>
<li>
<p>Run Busy loop (mandelbrot set) with a low load of 100microseconds. This
should migrate the task to slow CPU. Get CPU affinity of the task that is
running through the <code>sched_getaffinity</code> system call and verify the same. Sleep
for 500milliseconds and Busy loop for 100microseconds. Repeat this for few
times. We still expect ourselves to be in slow CPU since the load is low. Check
the same through the system call.</p>
</li>
<li>
<p>Now run the busy loop for 2 seconds. This should migrate the task to fast
CPU. Get CPU affinity of the task that is running through the
<code>sched_getaffinity</code> system call and verify the same.</p>
</li>
<li>
<p>These steps are carried out for 20 times for stability of affinity for 0 to
max number of CPUs.</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behaviour is to that there are no vulnerabilities present in the
scheduler.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_chew">3.9.2. chew</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is to test the scheduler of any vulnerabilities which might be present
with or without big.LITTLE MP scheduler extensions.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>These tests are taken from LWN.net</p>
</div>
<div class="paragraph">
<p>This test checks that when the Round Robin Scheduling algorithm is used, the
scheduler executes the tasks between regular intervals. The scheduler latency
which is set in the beginning to 2ms through <code>cat
/proc/sys/kernel/sched_latency_ns</code>. The quantum is set by <code>sched_rr_interval</code>
call to 8seconds.</p>
</div>
<div class="paragraph">
<p>This test gets the Round Robin time quantum for the calling process for 8
seconds run window, repeated in a loop 6 times after sleeping every 2 seconds
between loops.  Within an 8 sec execution window we are checking if the time
threshold between the RR time quantum obtained is &lt; 2ms. If not it is reported
a failure.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behaviour is to that there are no vulnerabilities present in the
vanilla scheduler.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_cpuhog">3.9.3. cpuhog</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is to test the scheduler of any vulnerabilities which might be present
with or without big.LITTLE MP scheduler extensions.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>These tests are taken from LWN.net</p>
</div>
<div class="paragraph">
<p>The purpose of this test is to create a set of processes that are going to load
the runqueue with different cache drain values and check if the kernel doesnot
fail.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The number of tasks are taken from the user. The children registers to
SIGHUP signal, incrementing a volatile SPIN variable to keep count.</p>
</li>
<li>
<p>The forked children goes on an infinite loop of CPU hog which basically does
memory operations depending on the cache line size.  The cache line is either
32 or 16. The memory operations are done on a register pointer variable such
that cache is being used. These operations happen with a high priority set by
NICE value after checking if the SPIN variable is set.</p>
</li>
<li>
<p>The parent sends signal SIGHUP to all the children which are cpuhogging and
thus exits gracefully.</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behaviour is to that there are no vulnerabilities present in the
scheduler.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_fiftyp">3.9.4. fiftyp</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is to test the scheduler of any vulnerabilities which might be present
with or without big.LITTLE MP scheduler extensions.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>These tests are taken from LWN.net</p>
</div>
<div class="paragraph">
<p>The test validates the scheduler behaviour when the CPU is running tasks, the
CPU is oscillating between 50% load and idle periods.</p>
</div>
<div class="paragraph">
<p>The test forks 2 separate child process. In both these processes it calls in an
infinite loop which invokes a <em>compute</em> task for loops equivalent to 7000 usec
(7 msec) followed by <em>idle</em> task for equivalent of 7000 usec (7 msec).</p>
</div>
<div class="paragraph">
<p>To produce 7msec equivalent of load, It uses burn_loops method to simply
increment in a loop with a compiler inline directive not to reorder
instructions as part of any optimisation. This loop is calibrated to 1%
tolerance and the load per msec for the CPU is calculated in terms of the
loops.</p>
</div>
<div class="paragraph">
<p>In the loop we try to benchmark how many meaningless loops per second we can
perform on this hardware to fairly accurately reproduce certain percentage cpu
usage</p>
</div>
<div class="paragraph">
<p>This is called a 50% test where 50% of time there is a CPU load and for the
rest there is CPU idle period.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behaviour is to that there are no vulnerabilities present in the
vanilla scheduler.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_hackbench">3.9.5. hackbench</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is to test the scheduler of any vulnerabilities which might be present with
or without big.LITTLE MP scheduler extensions.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>These tests are taken from LWN.net</p>
</div>
<div class="paragraph">
<p>Hackbench is both a benchmark and a stress test for the Linux kernel scheduler.
It&#8217;s main job is to create a specified number of pairs of  schedulable
entities (either  threads or traditional processes) which communicate via
either sockets or pipes and time how long it takes for each pair to send data
back and forth.  It is a general scheduler benchmark that is sensitive to
regressions in the scheduler fast-path.</p>
</div>
<div class="paragraph">
<p>In the initialisation phase it creates <em>n</em> groups of 20 receiver child process
and 20 sender child process, connected via 20 separate pipes/socket streams,
where <em>n</em> is user specified number of groups or defaulted to a value.</p>
</div>
<div class="paragraph">
<p>It Tests groups of 20 processes spraying to 20 receivers. It Waits for all
processes to be ready. It Creates the pipe between client and server. And then,
Sender sprays loop messages down each file descriptor. After that, it Reaps
them all.</p>
</div>
<div class="paragraph">
<p>When all the receiver and sender child process' are ready, then the test would
trigger (by writing into one of the 2 fds setup in the main process) the
writing of 100 characters each by all the sender child process to the receiver
child process via its own pipe/socket stream The process then waits for all the
number of spawned receiver and sender child process to terminate (simply
counting/waiting for the number of thread it initially spawned to signal
termination).</p>
</div>
<div class="paragraph">
<p>This test fundamentally computes the performance of this data traffic by
measuring the time taken for all the groups of sender-receivers sending this
100 bytes across multiple pipes.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behaviour is to that there are no vulnerabilities present in the
scheduler.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_irman2">3.9.6. irman2</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is to test the scheduler of any vulnerabilities which might be present
with or without big.LITTLE MP scheduler extensions.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>These tests are taken from LWN.net</p>
</div>
<div class="paragraph">
<p>This test is a load generator. It creates a huge number of pipes and forks the
same number of child processes and keep indefinitely doing pipe reads an writes
and hogs the CPU by mem copy operations across the main process and the
numerous threads created.</p>
</div>
<div class="paragraph">
<p>The test cases could be mem load, swap area enabled and testing process
stability. Another test case could be wrong priority calculation which is a
negative test case for this.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behaviour is to that there are no vulnerabilities present in the
scheduler.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="_main_pth_str01">3.9.7. main_pth_str01</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is to test the scheduler of any vulnerabilities which might be present
with or without the big.LITTLE MP scheduler extensions.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>These tests are taken from LWN.net</p>
</div>
<div class="paragraph">
<p>The scheduler is the kernel component that decides which runnable thread
will be executed by the CPU next. Each thread has an associated scheduling
policy and a static scheduling priority, sched_priority. The scheduler makes
its decisions based on knowledge of the scheduling policy and static priority
of all threads on the system.</p>
</div>
<div class="paragraph">
<p>Conceptually, the scheduler maintains a list of runnable threads for each
possible sched_priority value. In order to determine which thread runs next,
the scheduler looks for the nonempty list with the highest static priority and
selects the thread at the head of this list.</p>
</div>
<div class="paragraph">
<p>A thread&#8217;s scheduling policy determines where it will be inserted into the list
of threads with equal static priority and how it will move inside this list.</p>
</div>
<div class="paragraph">
<p>The test pth_str01 stresses the scheduler to pick next task.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Main program takes the arguments breadth and depth of the tree to be made.
It accordingly Allocates array of pthreads descriptors and initialize variables
like node mutex and node condition variables. It creates main/root thread and
waits for it to exit.</p>
</li>
<li>
<p>Root thread spawns a function to create children of depth and siblings of
breadth. This function needs to synchronize if all the siblings have been
created. This happens on a conditional wait using conditions (sends signal to
parent) and mutex (unlocks after signal is got). If all the siblings have been
created and it is not a leaf, next level children are created, else
synchronization is done, tree is created,  Wait for our children to finish
before the root exits.</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behaviour is to that there are no vulnerabilities present in the
scheduler.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_main_pth_str02">3.9.8. main_pth_str02</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is to test the scheduler of any vulnerabilities which might be present
with or without big.LITTLE MP scheduler extensions.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>These tests are taken from LWN.net</p>
</div>
<div class="paragraph">
<p>The scheduler is the kernel component that decides which runnable     thread
will be executed by the CPU next.  Each thread has an     associated scheduling
policy and a static scheduling priority,   sched_priority.  The scheduler makes
its decisions based on knowledge of the scheduling policy and static priority
of all threads on the system.</p>
</div>
<div class="paragraph">
<p>Conceptually, the scheduler maintains a list of runnable threads for  each
possible sched_priority value.  In order to determine which     thread runs
next, the scheduler looks for the nonempty list with the highest static
priority and selects the thread at the head of this   list.</p>
</div>
<div class="paragraph">
<p>A thread&#8217;s scheduling policy determines where it will be inserted   into the
list of threads with equal static priority and how it will  move inside this
list.</p>
</div>
<div class="paragraph">
<p>The test pth_str02 stresses the scheduler to pick next task.</p>
</div>
<div class="paragraph">
<p>This is a simple program which creates n number of threads recursively and
exits. There is a limit to creating the threads in the system, that is notified.
Since threads are a separate schedulable entities, the Number of threads that
are scheduled are printed and noted.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behaviour is to that there are no vulnerabilities present in the
scheduler.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_main_pth_str03">3.9.9. main_pth_str03</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is to test the scheduler of any vulnerabilities which might be present
with or without big.LITTLE MP scheduler extensions.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>These tests are taken from LWN.net</p>
</div>
<div class="paragraph">
<p>The scheduler is the kernel component that decides which runnable     thread
will be executed by the CPU next.  Each thread has an     associated scheduling
policy and a static scheduling priority,   sched_priority.  The scheduler makes
its decisions based on knowledge of the scheduling policy and static priority
of all threads on the system.</p>
</div>
<div class="paragraph">
<p>Conceptually, the scheduler maintains a list of runnable threads for  each
possible sched_priority value.  In order to determine which     thread runs
next, the scheduler looks for the nonempty list with the highest static
priority and selects the thread at the head of this   list.</p>
</div>
<div class="paragraph">
<p>A thread&#8217;s scheduling policy determines where it will be inserted   into the
list of threads with equal static priority and how it will  move inside this
list.</p>
</div>
<div class="paragraph">
<p>The test pth_str03 stresses the scheduler to pick next task. It is similar to
pth_str01 except that it keeps a count of the children that are under the
parent at each level.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Main program takes the arguments breadth and depth of the tree to be made.
It accordingly Allocates array of pthreads descriptors and initialize variables
like node mutex and node condition variables. It creates main/root thread and
waits for it to exit.</p>
</li>
<li>
<p>Root thread spawns a function to create children of depth and siblings of
breadth. This function needs to synchronize if all the siblings have been
created. This happens on a conditional wait. If all the siblings have been
created and it is not a leaf, next level children are created, else
synchronization is done, tree is created,  Wait for our children to finish
before we exit ourselves.</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behaviour is to that there are no vulnerabilities present in the
scheduler.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_migrate_time">3.9.10. migrate_time</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is to test the scheduler of any vulnerabilities which might be present with
or without big.LITTLE MP scheduler extensions.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>These tests are taken from LWN.net</p>
</div>
<div class="paragraph">
<p>This test checks if the migration happen over time when the affinity is changed
to certain CPUs.</p>
</div>
<div class="paragraph">
<p>In a Do While loop, current time is calculated and assigned to last. Previous
time is kept track in the previous loop. This loop is executed till difference
between the start time and the current time is less than the number of seconds
specified for migration. In this loop,everytime the loop enters, the <code>CPU</code> is
switched to <code>CPU+1</code>,  that is the next CPU until max number of CPUs are
covered.  Hence migration happens over time to different CPUs till the number
of seconds specified pass.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behaviour is to that there are no vulnerabilities present in the
scheduler.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_onetwotest">3.9.11. onetwotest</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is to test the scheduler of any vulnerabilities which might be present
with or without big.LITTLE MP scheduler extensions.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>These tests are taken from LWN.net</p>
</div>
<div class="paragraph">
<p>This test is to check the behaviour of the interativity of the scheduler. The
scheduler has to schedule all the processes and not hog one process.</p>
</div>
<div class="paragraph">
<p>This test is a simple 2 processes creating threads and waiting for those
threads to be terminated, writing in one pipe and reading in the other pipe.
The order of scheduling these two threads is checked for behaviour.</p>
</div>
<div class="paragraph">
<p>The main process forks a child process. Both parent and child processes
indefinitely creates a thread and waits for that thread to be terminated.
Everytime a thread is created and while being waited for it to terminate both
the parent process and the child process prints out a unique process id.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behaviour is to that there are no vulnerabilities present in the
scheduler.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_pipe_test">3.9.12. pipe_test</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is to test the scheduler of any vulnerabilities which might be present
with or without big.LITTLE MP scheduler extensions.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>These tests are taken from LWN.net</p>
</div>
<div class="paragraph">
<p>This test case is similar to pipe-test.c this test will run for 500000 loops
and prints the usec/loop and return.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Main process forks child process. Parent writes on pipe on one end and
child will read from the other end of the pipe. Thereafter, the child writes
back to the parent another message.</p>
</li>
<li>
<p>This will iterate for 500000 loops and time will be calculated before first
loop and end of the last loop and the time difference by number of loops will
be printed as the number of usec/loop.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The number of schedulable entities is limited but the way it is scheduled is
observed here.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behaviour is to that there are no vulnerabilities present in the
scheduler.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_pipe_test_1m">3.9.13. pipe_test_1m</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is to test the scheduler of any vulnerabilities which might be present
with or without big.LITTLE MP scheduler extensions.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>These tests are taken from LWN.net</p>
</div>
<div class="paragraph">
<p>This test case is similar to pipe-test.c this test will run for 1000000 loops
and prints the usec/loop and return.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Main process forks child process. Parent writes on pipe on one end and
child will read from the other end of the pipe. Thereafter, the child writes
back to the parent another message.</p>
</li>
<li>
<p>This will iterate for 1000000 loops and time will be calculated before first
loop and end of the last loop and the time difference by number of loops will
be printed as the number of usec/loop.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The number of schedulable entities is limited but the way it is scheduled is
observed here.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behaviour is to that there are no vulnerabilities present in the
scheduler.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_starve">3.9.14. starve</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is to test the scheduler of any vulnerabilities which might be present
with or without big.LITTLE MP scheduler extensions.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>These tests are taken from LWN.net</p>
</div>
<div class="paragraph">
<p>Starvation is usually caused by an overly simplistic scheduling algorithm. For
example, if a (poorly designed) multi-tasking system always switches between
the first two tasks while a third never gets to run, then the third task is
being starved of CPU time.</p>
</div>
<div class="paragraph">
<p>The main process forks a child process which keeps on sending a userdefined
signal to the parent process indefinitely until it is killed by the parent.The
main/parent process registers the handler for the userdefined signal (which
gets triggered by the child process) where it decrements a loop counter upon
which the parent process waits between sleeps. Once the parent process has
received enough signals from the child process to exit the loop counter it
explicitly kills the child process and terminates.</p>
</div>
<div class="paragraph">
<p>Here the test is a poorly designed multi-tasking system where the child is
always sending signals to the parent.  The child process keep on sending user
defined signals to the parent process continuously so as to <em>starve</em> the parent
process of scheduling opportunities to handle the signal and come out of the
loop.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behaviour is to that there are no vulnerabilities present in the
scheduler.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_tenp">3.9.15. tenp</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is to test the scheduler of any vulnerabilities which might be present
with or without big.LITTLE MP scheduler extensions.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>These tests are taken from LWN.net</p>
</div>
<div class="paragraph">
<p>The aim of the test is to validate scheduler behaviour where there is a 10%
load distribution between different processes.</p>
</div>
<div class="paragraph">
<p>This is like fiftyp except that it is for load of 10%.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Test starts by calibrating the CPU load characteristics on the platform. It
uses burn_loops method to simply increment in a loop with a compiler inline
directive not to reorder instructions as part of any optimisation.</p>
</li>
<li>
<p>Start with assumption of 10^6 loops possible to execute in a millisecond
(Assuming that if the clock speed is 1 GHz it could run 10^9 instructions in a
second and hence this initial assumption of 10^6 instructions for a msec).</p>
</li>
<li>
<p>In a loop execute this initial 10^6 instructions, Time the execution in nsec
and compute the actual number of instructions (rather loops) that was actually
executed in 1 msec. The number of loops (load) required to acheive a 1 msec
execution time is computed within a tolerance of 1%.</p>
</li>
<li>
<p>After some sleep this load for 1 msec execution is again recomputed one more
time within a 5% tolerance of 1 msec execution time. However this time the
number of loops is not changed if fallen within the tolerance. Else the whole
calibration is repeated with the current number of computed loop.</p>
</li>
<li>
<p>After some sleep compute the runtime duration for 1 msec. Also calibrate the
time for 1 msec sleep duration.</p>
</li>
<li>
<p>At this point calibration ends. What we get at the end of calibration is the
following a. Calibrated number of loops required for executing a 1 msec task b.
Calibrate runtime for 1 msec load c. Calibrated time for 9 msec sleep</p>
</li>
<li>
<p>After calibration is done, the test forks 14 separate child process. In all
the 14 processes it calls in an infinite loop which invokes a <em>compute</em> task
for loops equivalent to 1 msec followed by <em>idle</em> task for equivalent of 9
msec.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Since each of the process has a 1 msec <em>load</em> followed by 9 msec sleep window,
with sufficient number of competing processes there is a 1 + 9 = 10 windows of
opportunity for schedule to schedule between threads.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behaviour is to that there are no vulnerabilities present in the
scheduler.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_testcase">3.9.16. testcase</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is to test the scheduler of any vulnerabilities which might be present
with or without big.LITTLE MP scheduler extensions.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>These tests are taken from LWN.net</p>
</div>
<div class="paragraph">
<p>In this test, the main thread writes to a global pipe, and the child threads
read from the global pipe. The number of threads created are 16.  The child
thread does some CPU intensive task before reading the pipe.  It calculates the
value of (1+k) * (1-k) and <code>squareroot</code> of k where k is a <code>double</code>. Before the
parent makes the <code>volatile variable</code> <code>run</code> as zero, the thread would have read
from the pipe and the loop comes out for the child.  The parent sleeps for 3
seconds and writes to the global pipe before making the <code>run</code> variable to zero
for about 6 * 10^9 us. That is the calibrated time it takes to calculate the k.</p>
</div>
<div class="paragraph">
<p>The scheduler behaviour is observed for the way the threads are scheduled.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behaviour is to that there are no vulnerabilities present in the
scheduler.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_test_failed">3.9.17. test_failed</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Check the sanity of the regression test suite framework itself.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This test checks if the return value is 1.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The test return the value 1.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<img src="./images/icons/note.png" alt="Note">
</td>
<td class="content">
<div class="title">Possible Issues</div>
This test <strong>is expected</strong> to fail.
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="test_test_success">3.9.18. test_success</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Check the sanity of the regression test suite framework itself.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This test checks if the return value is 0.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The test return the value 0.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_thud">3.9.19. thud</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is to test the scheduler of any vulnerabilities which might be present
with or without big.LITTLE MP scheduler extensions.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>These tests are taken from LWN.net</p>
</div>
<div class="paragraph">
<p>Skips occur when more than one interactive task starts to become a CPU hog. The
test case tries to reproduce this by creating a number of tasks which alternate
between being <em>interactive</em> and CPU hogs.</p>
</div>
<div class="paragraph">
<p>The thud program is a short piece of code written to allow other kernel
developers to reliably reproduce a specific problem with the scheduler - that
is, when only a small number of maximally interactive tasks suddenly become CPU
hogs they were able to starve most other processes for several seconds.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>After initialization of some memory for doing memcopy operations as a CPU
bound task the main process forks user specified number of child processes.
each of the child processes puts themselves to the back of the scheduler Q with
a sched_yield call.</p>
</li>
<li>
<p>After this every process would sleep for 10.5 sec followed by a memcopy
operation for about 6 seconds. This activity is repeated for 10 times.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The parent waits to kill the children while the children are busy looping never
giving a chance to the parent.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behaviour is to that there are no vulnerabilities present in the
scheduler.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="thud2">3.9.20. thud2</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This is to test the scheduler of any vulnerabilities which might be present
with or without big.LITTLE MP scheduler extensions.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>These tests are taken from LWN.net</p>
</div>
<div class="paragraph">
<p>Skips occur when more than one interactive task starts to become a CPU hog. The
test case tries to reproduce this by creating a number of tasks which alternate
between being <em>interactive</em> and CPU hogs.</p>
</div>
<div class="paragraph">
<p>The thud program is a short piece of code written to allow other kernel
developers to reliably reproduce a specific problem with the scheduler - that
is, when only a small number of maximally interactive tasks suddenly become CPU
hogs they were able to starve most other processes for several seconds.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>After initialization of some memory for doing memcopy operations as a CPU
bound task the main process forks user specified number of child processes.
each of the child processes puts themselves to the back of the scheduler Q with
a sched_yield call.</p>
</li>
<li>
<p>Same logic as thud.c except for here it sleeps for 10 seconds with multiple
calls to nanosleep over a loop.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The parent waits to kill the children while the children are busy looping never
giving a chance to the parent.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behaviour is to that there are no vulnerabilities present in the
scheduler.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="suite_scaleinvariance">3.10. "Scale Invariance" Test Suite</h3>
<div class="paragraph">
<div class="title">Goal</div>
<p>The primary aim of the test cases within scaleinvariance_suite is to validate
behaviour of scale invariance support for scheduler in a big.LITTLE system.</p>
</div>
<div class="paragraph">
<p>To start the execution of just this test:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-run scaleinvariance</code></pre>
</div>
</div>
<div class="paragraph">
<p>Following is the list of supported tests</p>
</div>
<div class="sect3">
<h4 id="test_scalinv_test_0001">3.10.1. scalinv_test_0001</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Checks if scale invariance can be turned on and off</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This test asserts the usage of load as a representation of the amount of
<strong>POTENTIAL</strong> CPU compute capacity used, as opposed to <code>CURRENT</code> CPU compute
capacity.</p>
</div>
<div class="paragraph">
<p>cpufreq is responsible for scale invariance management.  If CPUFreq is enabled,
scales load in accordance with frequency.</p>
</div>
<div class="paragraph">
<p>Different governors like Powersave / performance / ondemand / interactive/
userspace <code>CPUFreq governors</code> are available.</p>
</div>
<div class="paragraph">
<p>The governors and CPUFreq subsystem should correctly report the frequencies
available.</p>
</div>
<div class="paragraph">
<p>The debug interfaces used to get these information is
<code>/sys/kernel/hmp/scale_invariant_load</code> and
<code>/sys/devices/system/cpu/cpu0/topology/enable_scaled_cpupower</code>.</p>
</div>
<div class="paragraph">
<p>This test checks whether the prototype feature of CPU-power based scale and
frequency invariance is present or not and whether it is controllable or not.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_scalinv_test_0002">3.10.2. scalinv_test_0002</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Checks for presence of userspace governor in kernel</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>The userspace governor Leaves the <code>Operating Performance Point - OPP</code> selection
entirely to user-space. For example, a shell script might query the available
OPP range and request a transition to a specific OPP of its choice directly.
This is an invaluable tool for characterization of DVFS capability.</p>
</div>
<div class="paragraph">
<p>These information is got by the sys debug interfaces
<code>/sys/devices/system/cpu/cpu0/cpufreq/scaling_available_governors</code> and checked
for the string userspace to get the required information.</p>
</div>
<div class="paragraph">
<p>This test just checks for the presense of userspace in the available governors.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not supposed to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_scalinv_test_003">3.10.3. scalinv_test_003</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Test scheduler for errors without the scale invariance.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>Without scale invariance, change the freq every 1[s] and check that the
runnable ratio remains unchanged.  This means that the task is able to get the
CPU time in the same ratio for every one second when the CPU affinity is set
and priority is set greater than cut off priority.</p>
</div>
<div class="paragraph">
<p>The following tasks are done to assert the same.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Set time delay between frequency, set frequency of big cluster, set
frequency of LITTLE cluster.</p>
</li>
<li>
<p>Clear existing tasks from the LITTLE CPU. Set CPU affinity of this task to
the LITTLE CPU.</p>
</li>
<li>
<p>Set priority &gt; cutoff priority.</p>
</li>
<li>
<p>Disable frequency-invariant load scaling</p>
</li>
<li>
<p>Run test with different frequencies available.</p>
</li>
<li>
<p>Test if the ratio value of within +/- 10 for all trace points.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Thus, this test checks if without the scheduler support for scale invariance,
and with frequency of 1[s], then runnable ratio of the task remains unchanged.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail</p>
</div>
</div>
<div class="sect3">
<h4 id="test_scalinv_test_004">3.10.4. scalinv_test_004</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Without invariance support, check that the frequency changes at each step and
the task load is unchanged</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This test checks if we manually change the frequencies when the scale
invariance is disabled, the task load remains unchanged when the frequencies
are changed at each step.</p>
</div>
<div class="paragraph">
<p>The following tasks are done to assert the same.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Determine Big Little CPUs in the system</p>
</li>
<li>
<p>Clear existing tasks from LITTLE CPU since we are testing on the LITTLE CPU.</p>
</li>
<li>
<p>Set Userspace governorns to access them, start task load and move it to
LITTLE CPU.</p>
</li>
<li>
<p>Disable the frequency invariant load scaling</p>
</li>
<li>
<p>Change the frequencies manually through
<code>/sys/devices/system/cpu/cpu${TARGET_LITTLE_CPU}/cpufreq/scaling_setspeed</code> and
set the delay to 1ms</p>
</li>
<li>
<p>Check the traces if the task load has not changed when the frequency is
changed</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Thus, this test checks that we be able to change the frequencies without the
invariance support and the task load is not scaled.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_scalinv_test_005">3.10.5. scalinv_test_005</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Cheks task load being scaled in line with frequency</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>This test checks if we manually change the frequencies when the scale
invariance is enabled, the task load also scales when the frequencies are
changed at each step.</p>
</div>
<div class="paragraph">
<p>The following tasks are done to assert the same.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Determine Big Little CPUs in the system</p>
</li>
<li>
<p>Clear existing tasks from LITTLE CPU since we are testing on the LITTLE CPU.</p>
</li>
<li>
<p>Set Userspace governorns to access them, start task load and move it to
LITTLE CPU.</p>
</li>
<li>
<p>Enable the frequency invariant load scaling</p>
</li>
<li>
<p>Change the frequencies manually through
<code>/sys/devices/system/cpu/cpu${TARGET_LITTLE_CPU}/cpufreq/scaling_setspeed</code> and
set the delay to 1ms</p>
</li>
<li>
<p>Check the traces if the task load has changed in line with the frequency
that is changed</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Thus, this test checks that the tracked load (after settling) scales is in line
with the frequency - we have a range of +/- 1 unit because it&#8217;s not always
exact</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="suite_taskpacking">3.11. "TaskPacking" Test Suite</h3>
<div class="paragraph">
<div class="title">Goal</div>
<p>The primary aim of the test cases within taskpacking_suite is to validate the
functional behaviour of small task packing feature.</p>
</div>
<div class="paragraph">
<p>To start the execution of just this test:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-run taskpacking</code></pre>
</div>
</div>
<div class="paragraph">
<p>Following is the list of supported tests</p>
</div>
<div class="sect3">
<h4 id="test_pack_single_cpu">3.11.1. pack_single_cpu</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>This tests for the behaviour of the small task packing.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>Considering an MP3 Playback program as the use case for this test, all the
small tasks consuming less power and periodic in nature with short execution
time, such as play ringtones, alarms or message tones, play mp3 or fm. These
tasks disturb CPUs in deep sleep which is bad for power consumption. These
tasks can be identified using load_contrib. All these tasks should be packed in
one LITTLE CPU, the packing buddy. While packing, a threshold is seen for the
task load and the tasks are migrated to the packing buddy if the load is less
than the threshold.</p>
</div>
<div class="paragraph">
<p>The performance impact shoud be none or negligible and the power/less energy
should be consumed.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Start Light load threads using cyclic threads program</p>
</li>
<li>
<p>Enable small task packing and set the packing limit to 1024</p>
</li>
<li>
<p>Check if all the threads are running on the small task CPU by checking the
thread IDs against the CPU list of the running thread.</p>
</li>
<li>
<p>After results, restore packing limit and packing state.</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>Use light load threads to confirm all the light weight threads are packed on to
a single LITTLE CPU</p>
</div>
<div class="olist arabic">
<div class="title">Possible Issues</div>
<ol class="arabic">
<li>
<p>the scheduler calculates the load in an incorrect manner</p>
</li>
<li>
<p>the migration doesnot happen for some reason</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="suite_thresholds">3.12. "Thresholds" Test Suite</h3>
<div class="paragraph">
<div class="title">Goals</div>
<p>The migration thresholds define two of the main big.LITTLE MP scheduler
extensions' parameters which allows to identify when a task should be moved
between a big and a LITTLE cluster.
A proper tuning of these thresholds if of paramount importance to get expected
and optimal behaviors from the big.LITTLE MP scheduler.</p>
</div>
<div class="paragraph">
<p>However, thresholds tuning is delicate operation and perhaps not even an "exact
science".  Certain thresholds combinations could be suitable for some use-cases
but sub-optimal for others.  For these reasons some big.LITTLE MP integrators provides
scenario based tuning where the thresholds are adapted at run-time based on the
specific usage scenarios in order to boost performances or reduce energy
consumption.</p>
</div>
<div class="paragraph">
<p>Without considering all the possible run-time tuning scenarios, there are some
basic checks which could still be done on thresholds and that allows to
investigate for potential and common misconfiguration which affects even a
simple integration of the big.LITTLE MP scheduler.</p>
</div>
<div class="paragraph">
<p>The goal of this test suite is to support the user on identify these common
misconfiguration scenarios and issue warning to support their fix.</p>
</div>
<div class="paragraph">
<p>To start the execution of just this test:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-run thresholds</code></pre>
</div>
</div>
<div class="paragraph">
<p>Following is the list of supported tests</p>
</div>
<div class="sect3">
<h4 id="test_thresholds_basic">3.12.1. thresholds_basic</h4>
<div class="paragraph">
<div class="title">Goals</div>
<p>Check for common migration threshold misconfigurations</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>Up and Down migration thresholds must be configured to reasonable values which
almost never correspond to the boundaries of their range.</p>
</div>
<div class="paragraph">
<p>If the up migration threshold is configured to be 1023, than a task will never
be up-migrated unless it fully uses a LITTLE CPU running at its highest OPP.
This is not in general a severe misconfiguration but it could impact on the
responsiveness of the system to move high CPU demanding tasks on a big CPU.
It is worth to consider that, by default, the big.LITTLE MP scheduler
extensions spawn new tasks on big CPUs, thus this latency on up migration does
not apply to newly created big tasks. The latency affects just the up migration
of already running tasks which change their execution pattern at run-time to
become more CPU intensive.</p>
</div>
<div class="paragraph">
<p>If the down migration threshold is configured to be 1023, than all tasks will
be always migrated to LITTLE CPUs, which is a severe misconfiguration.
A 0 down migration threshold as well has to be considered a severe
misconfiguration. Indeed, in that case, all active tasks will never be migrated
down from big cluster. If we consider that new tasks are always fork migrated on
big CPUs, this means that a 0 down migration threshold will enforce all tasks
to always run on big CPUs.</p>
</div>
<div class="paragraph">
<p>As a final remark, in general the up migration threshold is expected to have a
value which is lower than that of the down migration. This is because once a
task, with a certain CPU load demand, is up migrated we could eventually expect
that its CPU demand will decrease since it is running on a more capable big
core. Thus, to avoid tasks oscillations between big and LITTLE clusters, the
two thresholds are expected to satisfy the equation:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>up_threshold &gt; down_threshold</pre>
</div>
</div>
<div class="paragraph">
<p>This test provides all the checks for the aforementioned basic thresholds
configuration.</p>
</div>
<div class="olist arabic">
<div class="title">Possible issues</div>
<ol class="arabic">
<li>
<p>at least one threshold configured to the saturation value</p>
</li>
<li>
<p>overlapping thresholds values</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="suite_usecases">3.13. "Use-Cases" Test Suite</h3>
<div class="paragraph">
<div class="title">Goals</div>
<p>The main goal of this test suite is to evaluate the behaviors of the big.LITTLE
MP scheduler extensions patchset once commonly used workloads are executed on a
target system.</p>
</div>
<div class="paragraph">
<p>All the use cases tested by this suite are generated using the syntetic
workload generator based on rt-app provided by Linaro:
<a href="https://wiki.linaro.org/WorkingGroups/PowerManagement/Resources/Tools/WorkloadGen" class="bare">https://wiki.linaro.org/WorkingGroups/PowerManagement/Resources/Tools/WorkloadGen</a></p>
</div>
<div class="paragraph">
<p>To start the execution of just this test:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-run usecases</code></pre>
</div>
</div>
<div class="paragraph">
<p>Following is the list of supported tests</p>
</div>
<div class="sect3">
<h4 id="test_00_smalltasks">3.13.1. SmallTasks</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Assert that small tasks workload runs only on LITTLE CPUs</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>A common usage scenario consisting of just small tasks is represented by the
playback of an Audio stream. Audio decoding and playback is usually performed
using a set of tasks which builds up a processing pipeline.
These tasks are usually relatively low CPU demanding and are expected to be
executed just on LITTLE cpus.</p>
</div>
<div class="paragraph">
<p>An example audio decoding pipeline is provided by the rt-app workload
generator and it is defined by the <code>mp3.json</code> configuration file.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behavior is reported in the following figure:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/usecases/usecases_00_smalltasks.png" alt="SmallTasks test case">
</div>
</div>
<div class="paragraph">
<p>Tasks composing the audio decoding pipeline are initially created on big CPUs,
<span class="green">green marker</span>, which is an expected behavior due to the FORK migration
mechanism enforced by the big.LITTLE MP scheduler extensions.
However, after ~100[ms] they are immediately migrated on LITTLE CPUs,
<span class="red">red marker</span>, and since this moment they will never get back to executed
on big CPUs.</p>
</div>
<div class="paragraph">
<p>In this example tasks of the pipeline are generating a load on LITTLE CPUs
which is in between 10-300. Thus, provided that the down migration threshold is
configured with a value higher than 300 these tasks are expected to be
certainly migrated to LITTLE CPUs.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<img src="./images/icons/note.png" alt="Note">
</td>
<td class="content">
300 is the load generated by the biggest pipeline task (i.e.
<code>AudioOut_2</code>) when running on a LITTLE core, thus the corresponding load when
the tasks are running on big CPUs is expected to be much less.
</td>
</tr>
</table>
</div>
<div class="olist arabic">
<div class="title">Possible issues</div>
<ol class="arabic">
<li>
<p>down migration threshold configured to small compared to the load generated
by the tasks composing the pipeline</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="test_01_rttasks">3.13.2. RT Tasks</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Assert that RT tasks workload runs only on LITTLE CPUs</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>Real-Time tasks are usually considered not CPU demanding activities while being
sensible to latencies. The big.LITTLE MP scheduler extensions enforce these
tasks to run on LITTLE CPUs where, thanks to their higher priority with respect
to CFS tasks, they are expected to have all the required computational
resources to satisfy their latency expectations.</p>
</div>
<div class="paragraph">
<p>An example of real-time workload is provided using the rt-app to simulate a set
of three RT tasks with different timing requirements and generated CPU load.</p>
</div>
<div class="paragraph">
<p>This testcase checks that all RT tasks in a system are always scheduler on
LITTLE CPUs independently from the actual load they generate.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behavior is reported in the following figure:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/usecases/usecases_01_rttasks.png" alt="RT tasks test case">
</div>
</div>
<div class="paragraph">
<p>Three tasks (SmallRT, MedRT and BigRT) are generated since the beginning,
<span class="green">green marker</span>, running on LITTLE CPUs.  The test is successfull is
these tasks are never moved to run on big CPUs.</p>
</div>
<div class="paragraph">
<p>It is worth to notice that the RT tasks could also generate a really high
workload, nevertheless they must never be migrated to big CPUs.</p>
</div>
<div class="olist arabic">
<div class="title">Possible issues</div>
<ol class="arabic">
<li>
<p>RT tasks are explicitly pinned on big CPUs by some user-space tools, i.e. not
because of an HMP migration events.</p>
</li>
<li>
<p>the priority filer support is disabled in the kernel in use,
check to have the CONFIG_SCHED_HMP_PRIO_FILTER option enabled</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="test_02_bigtasks">3.13.3. Big Tasks</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>Assert that big tasks workload runs on big CPUs as soon as possible.</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>Big tasks are always expected to run on big CPUs as soon as one of such CPUs is
available.  Indeed, the big.LITTLE MP scheduler extensions enforce just a
single big task per big CPU at each time, in order to optimize its performance
by reducing contention on local resources with other tasks.</p>
</div>
<div class="paragraph">
<p>An example of a task workload suitable for a big CPU is provided by using
rt-app to simulate a number of batch tasks where the number is one more than
the number of big CPUs.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The expected behavior is reported in the following figure:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/usecases/usecases_02_bigtasks.png" alt="Big tasks test case">
</div>
</div>
<div class="paragraph">
<p>The platform used in this example is a big.LITTLE system with 4xA7 and 4xA15.
Thus, an initial set of 5 batch tasks are generated, <span class="green">green marker</span>, all
staring on big CPUs because of the FORK migration mechanism.
After ~80[ms], <span class="ref">red marker</span>, one of such batch tasks is migrated on the
LITTLE CPU 2. This allows 4 big tasks to run alone each one on a big CPU to
complete as soon as possible.
As soon as a big CPU becomes free, <span class="orange">orange marker</span>, the task previously
moved on CPU2 is immediately migrated on the now free CPU 6 thanks to the
IDLE-PULL migration mechanism.</p>
</div>
<div class="olist arabic">
<div class="title">Possible issues</div>
<ol class="arabic">
<li>
<p>down migration threshold saturated</p>
</li>
<li>
<p>other big tasks running while the experiment is executed</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="suite_ipa_functional">3.14. "IPA Functional" Test Suite</h3>
<div class="paragraph">
<div class="title">Goal</div>
<p>The primary goal of this tese suite is to perform basic functionality tests to
accomplish the following:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Check Instantiation of:</p>
<div class="ulist">
<ul>
<li>
<p>Cooling Devices</p>
</li>
<li>
<p>Thermal Trips</p>
</li>
<li>
<p>Thermal Zones</p>
</li>
</ul>
</div>
</li>
<li>
<p>Check if the sysfs directory structure is created as expected</p>
</li>
<li>
<p>Perform basic boundary condition check for cooling device states</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>To start the execution of just this test:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ schedtest-run functional</code></pre>
</div>
</div>
<div class="paragraph">
<p>Following is the list of supported tests:</p>
</div>
<div class="sect3">
<h4 id="test_001_check_tz_sysfs">3.14.1. 001_check_tz_sysfs</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>The goal of this test is to ascertain if the sysfs pararamaters are populated
correctly in for the thermal zone.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>The device is expected to have one thermal zone (index zero) and the following
files are expected to be in sysfs. These files donot include the files that
are populated by the the bound cooling devices and trip points:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Base Directory</p>
<div class="ulist">
<ul>
<li>
<p><code>/sys/class/thermal/thermal_zone0</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Files</p>
<div class="ulist">
<ul>
<li>
<p><code>integral_cutoff</code></p>
</li>
<li>
<p><code>k_d</code></p>
</li>
<li>
<p><code>k_i</code></p>
</li>
<li>
<p><code>k_po</code></p>
</li>
<li>
<p><code>k_pu</code></p>
</li>
<li>
<p><code>mode</code></p>
</li>
<li>
<p><code>policy</code></p>
</li>
<li>
<p><code>power</code></p>
</li>
<li>
<p><code>subsystem</code></p>
</li>
<li>
<p><code>sustainable_power</code></p>
</li>
<li>
<p><code>temp</code></p>
</li>
<li>
<p><code>type</code></p>
</li>
<li>
<p><code>uevent</code></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail</p>
</div>
</div>
<div class="sect3">
<h4 id="test_002_check_cdevs">3.14.2. 002_check_cdevs</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>The primary goal of this test is to check if the cooling devices have been
populated correctly</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>IPA on Juno is expected to have three cooling devices and the following files
in each cooling device&#8217;s sysfs directory for indices 0, 1 and 2.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Base Directory</p>
<div class="ulist">
<ul>
<li>
<p><code>/sys/class/thermal/cooling_device&lt;index&gt;</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Files</p>
<div class="ulist">
<ul>
<li>
<p><code>cur_state</code></p>
</li>
<li>
<p><code>max_state</code></p>
</li>
<li>
<p><code>power</code></p>
</li>
<li>
<p><code>subsystem</code></p>
</li>
<li>
<p><code>type</code></p>
</li>
<li>
<p><code>uevent</code></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail</p>
</div>
</div>
<div class="sect3">
<h4 id="test_003_check_cpufreq_cooling">3.14.3. 003_check_cpufreq_cooling</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>The goal of this test is to check if the cpufreq cooling devices are
instantiated correctly</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>JUNO has two cpufreq domains and is expected to have two cpufreq cooling
devices</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail</p>
</div>
</div>
<div class="sect3">
<h4 id="test_004_check_devfreq_cooling">3.14.4. 004_check_devfreq_cooling</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>The goal of this test is to check if the devfreq cooling device(s) have been
instantiated properly</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>JUNO is expected to have one devfreq cooling device for the GPU</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail</p>
</div>
</div>
<div class="sect3">
<h4 id="test_005_check_trip_points">3.14.5. 005_check_trip_points</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>The goal of this test is to check if the trip points have been created
correctly.</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>JUNO is expected to have two trip points. For the indices 0 and 1 the following
files must exist</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Base Directory</p>
<div class="ulist">
<ul>
<li>
<p><code>/sys/class/thermal/thermal_zone0</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Files</p>
<div class="ulist">
<ul>
<li>
<p><code>trip_point_&lt;index&gt;_type</code></p>
</li>
<li>
<p><code>trip_point_&lt;index&gt;_temp</code></p>
</li>
<li>
<p><code>trip_point_&lt;index&gt;_hyst</code></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail</p>
</div>
</div>
<div class="sect3">
<h4 id="test_006_check_tz_cdevs">3.14.6. 006_check_tz_cdevs</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>The goal of this test is to check if the cooling devices are bound to the
thermal_zone</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>All the three cooling devices 0, 1 and 2 are expected to be bound to the
thermal_zone0.  The following files must exists for this test to succeed.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Base Directory</p>
<div class="ulist">
<ul>
<li>
<p><code>/sys/class/thermal/thermal_zone0</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Files</p>
<div class="ulist">
<ul>
<li>
<p><code>cdev&lt;index&gt;</code> (link to the cooling device)</p>
</li>
<li>
<p><code>cdev&lt;index&gt;_weight</code></p>
</li>
<li>
<p><code>cdev&lt;index&gt;_trip_point</code></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail</p>
</div>
</div>
<div class="sect3">
<h4 id="test_007_check_tz_cdev_trips">3.14.7. 007_check_tz_cdev_trips</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>The goal of this test is to check if the cooling devices are associated to the
correct trip points</p>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>All the cooling devices 0, 1 and 2 are expected to be associated to the trip
point 1.  The association can be found by reading the file
<code>/sys/class/thermal/thermal_zone0/cdev&lt;index&gt;_trip_point</code></p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail</p>
</div>
</div>
<div class="sect3">
<h4 id="test_008_high_control_high_trigger">3.14.8. 008_high_control_high_trigger</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>The goal of this test is to check if basic IPA functionality in boundary
conditions</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>In our setup:<br></p>
</div>
<div class="ulist">
<ul>
<li>
<p>The trip point 0 represents the temperature when IPA starts monitoring the
power allocation actively</p>
</li>
<li>
<p>The the trip point 1 represents the temperature where the the cooling devices
0, 1 and 2 come into effect</p>
</li>
</ul>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>As both the trip points are set to high value, the cooling devices states are
expected to remain 0.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail</p>
</div>
</div>
<div class="sect3">
<h4 id="test_009_low_control_high_trigger">3.14.9. 009_low_control_high_trigger</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>The goal of this test is to check basic IPA functionality in boundary
conditions</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>In our setup:<br></p>
</div>
<div class="ulist">
<ul>
<li>
<p>The trip point 0 represents the temperature when IPA starts monitoring the
power allocation actively</p>
</li>
<li>
<p>The the trip point 1 represents the temperature where the the cooling devices
0, 1 and 2 come into effect</p>
</li>
</ul>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>Although the first trip point is set to a low value, the second trip point
which activates the cooling devices in our setup is relatviely high. The
cooling device states are expected to be 0.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>In some versions of Juno LSK, this test can fail with an output
similar to the following:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Checking cdev_id: 0 (devfreq)
Failed: cur_state for devfreq is 4
Checking cdev_id: 1 (thermal-cpufreq-0)
Passed: cur_state for  thermal-cpufreq-0 is 0
Checking cdev_id: 2 (thermal-cpufreq-1)
Passed: cur_state for  thermal-cpufreq-1 is 0
Fatal error: an unexpected error has occurred!</pre>
</div>
</div>
<div class="paragraph">
<p>devfreq is the cooling device for the GPU.  If the GPU doesn&#8217;t have
any load, the devfreq cooling device may decide to reduce its
frequency even if the control temperature is high and there is thermal
budget.  This is not a problem because as soon as there is any load,
the GPU would get all the power.  Unfortunately, this test is usually
run with the GPU idling and that&#8217;s why it can fail.  This is
a false-positive.</p>
</div>
</div>
<div class="sect3">
<h4 id="test_010_low_control_low_trigger">3.14.10. 010_low_control_low_trigger</h4>
<div class="paragraph">
<div class="title">Goal</div>
<p>The goal of this test is to check if basic IPA functionality in boundary
conditions</p>
</div>
<div class="paragraph">
<div class="title">Detailed Description</div>
<p>In our setup:<br></p>
</div>
<div class="ulist">
<ul>
<li>
<p>The trip point 0 represents the temperature when IPA starts monitoring the
power allocation actively</p>
</li>
<li>
<p>The the trip point 1 represents the temperature where the the cooling devices
0, 1 and 2 come into effect</p>
</li>
</ul>
</div>
<div class="paragraph">
<div class="title">Expected Behavior</div>
<p>Since both the trip points are set to a very low value. All the cooling devices
are expected to be in their respective <code>max_state</code>.</p>
</div>
<div class="paragraph">
<div class="title">Possible Issues</div>
<p>This test is not expected to fail</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2015-04-23 17:10:18 BST
</div>
</div>
</body>
</html>